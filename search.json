[
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "🎉 Thank you for checking out our project! 🎉\nThis page contains guidelines on how to get in touch with us and potentially contribute towards this repository.\n\n\nYou can contact the researchers on this project using the provided email addresses in CITATION.cff.\n\n\n\nIf you spot an issue, you are welcome to raise this either by:\n\nUsing GitHub Issues.\nForking the repository, make your changes and submit a pull request for review."
  },
  {
    "objectID": "CONTRIBUTING.html#email",
    "href": "CONTRIBUTING.html#email",
    "title": "Contributing",
    "section": "",
    "text": "You can contact the researchers on this project using the provided email addresses in CITATION.cff."
  },
  {
    "objectID": "CONTRIBUTING.html#suggesting-changes",
    "href": "CONTRIBUTING.html#suggesting-changes",
    "title": "Contributing",
    "section": "",
    "text": "If you spot an issue, you are welcome to raise this either by:\n\nUsing GitHub Issues.\nForking the repository, make your changes and submit a pull request for review."
  },
  {
    "objectID": "reproduction/scripts/reproduction.html",
    "href": "reproduction/scripts/reproduction.html",
    "title": "Reproduction",
    "section": "",
    "text": "This notebook reproduces all the results from:\nIf running all scenarios from scratch, the total run time for this notebook is 49 minutes and 17 seconds. This time was from reproduction on an Intel Core i7-12700H with 32GB RAM running Ubuntu 22.04.4 Linux.\nThe individual run times for each scenario were: * Base (15% probability of secondary infection) - 7m 29s * Base with 5% probability of secondary infection - 5m 49s * Base with 30% probability of secondary infection - 8m 38s * Random shift assignment - 1m 45s * Protective measures: social distancing - 5m 21s * Protective measures: gloves - 5m 20s * Protective measures: surgical mask - 5m 5s * Protective measures: gown - 4m 51s * Protective measures: N95 mask - 4m 54s"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#set-up",
    "href": "reproduction/scripts/reproduction.html#set-up",
    "title": "Reproduction",
    "section": "Set-up",
    "text": "Set-up\nImport required packages\n\n# Import model\nimport model\n\n# Data processing and figure generation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Manage file paths\nfrom dataclasses import dataclass\nimport os\n\n# Hide warnings that appear\nimport warnings\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\nwarnings.filterwarnings('ignore')\n\n# To record runtime of this notebook\nimport time\n\nSet file paths\n\n@dataclass(frozen=True)\nclass Paths:\n    '''Singleton object for storing paths to data and database.'''\n\n    outputs = '../outputs'\n    base_5 = 'output_base5.csv'\n    base_15 = 'output_base15.csv'\n    base_30 = 'output_base30.csv'\n    no_rest = 'output_base15_norest.csv'\n    contact_half = 'output_base15_contact20.csv'\n    gloves = 'output_base15_gloves.csv'\n    surgical_mask = 'output_base15_surgicalmask.csv'\n    gown = 'output_base15_gown.csv'\n    n95_mask = 'output_base15_n95mask.csv'\n\n    paper = '../../original_study'\n    tab2 = 'supp_tab2_reformat.csv'\n    tab3 = 'supp_tab3_reformat.csv'\n    tab4 = 'supp_tab4_reformat.csv'\n    tab5 = 'supp_tab5_reformat.csv'\n    tab6 = 'supp_tab6_reformat.csv'\n    fig2 = 'fig2.png'\n    fig3 = 'fig3.png'\n    fig4 = 'fig4.png'\n    fig5 = 'fig5.png'\n\npaths = Paths()"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#run-model",
    "href": "reproduction/scripts/reproduction.html#run-model",
    "title": "Reproduction",
    "section": "Run model",
    "text": "Run model\n\nrun_model = False\n\n# Start timer if running models\nif run_model:\n    start = time.time()\n\nBase scenario (15% probability of secondary infection)\n\nif run_model:\n    # Run model\n    res = model.run_scenarios()\n    # Save results to CSV\n    res.to_csv(os.path.join(paths.outputs, paths.base_15), index=False)\n\nBase scenario with 5% probability of secondary infection\n\nif run_model:\n    # Run model\n    res = model.run_scenarios(secondary_attack_rate=0.05)\n    # Save results to CSV\n    res.to_csv(os.path.join(paths.outputs, paths.base_5), index=False)\n\nBase scenario with 30% probability of secondary infection\n\nif run_model:\n    # Run model\n    res = model.run_scenarios(secondary_attack_rate=0.3)\n    # Save results to CSV\n    res.to_csv(os.path.join(paths.outputs, paths.base_30), index=False)\n\nBase scenario (15% probability of secondary infection) with only one shift per day, and without a predefined minimum rest day after shifts (to simulate random shift assignment after each shift).\n\nif run_model:\n    # Run model\n    res = model.run_scenarios(shift_day=[1], rest_day=False)\n    # Save results to CSV\n    res.to_csv(os.path.join(paths.outputs, paths.no_rest), index=False)\n\nBase scenario (15% probability of secondary infection) with contact rate halved (to simulate effect of workplace social distancing)\n\nif run_model:\n    # Run model\n    res = model.run_scenarios(contact_rate=0.2)\n    # Save results to CSV\n    res.to_csv(os.path.join(paths.outputs, paths.contact_half), index=False)\n\nBase scenario with altered probability of secondary infection (to simulate workplace protective measures)\n\nif run_model:\n    # Run model\n    gloves = model.run_scenarios(secondary_attack_rate=0.15*0.45)\n    # Save results to csv\n    gloves.to_csv(os.path.join(paths.outputs, paths.gloves), index=False)\n\n\nif run_model:\n    # Run model\n    surgical_mask = model.run_scenarios(secondary_attack_rate=0.15*0.32)\n    # Save results to csv\n    surgical_mask.to_csv(os.path.join(paths.outputs, paths.surgical_mask), index=False)\n\n\nif run_model:\n    # Run model\n    gown = model.run_scenarios(secondary_attack_rate=0.15*0.23)\n    # Save results to csv\n    gown.to_csv(os.path.join(paths.outputs, paths.gown), index=False)\n\n\nif run_model:\n    # Run model\n    n95_mask = model.run_scenarios(secondary_attack_rate=0.15*0.09)\n    # Save results to csv\n    n95_mask.to_csv(os.path.join(paths.outputs, paths.n95_mask), index=False)"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#import-results",
    "href": "reproduction/scripts/reproduction.html#import-results",
    "title": "Reproduction",
    "section": "Import results",
    "text": "Import results\n\nmodel_base15 = pd.read_csv(os.path.join(paths.outputs, paths.base_15))\npaper_tab2 = pd.read_csv(os.path.join(paths.paper, paths.tab2))\n\nmodel_base5 = pd.read_csv(os.path.join(paths.outputs, paths.base_5))\npaper_tab3 = pd.read_csv(os.path.join(paths.paper, paths.tab3))\n\nmodel_base30 = pd.read_csv(os.path.join(paths.outputs, paths.base_30))\npaper_tab4 = pd.read_csv(os.path.join(paths.paper, paths.tab4))\n\nmodel_norest = pd.read_csv(os.path.join(paths.outputs, paths.no_rest))\npaper_tab5 = pd.read_csv(os.path.join(paths.paper, paths.tab5))\n\nmodel_contact = pd.read_csv(os.path.join(paths.outputs, paths.contact_half))\nmodel_gloves = pd.read_csv(os.path.join(paths.outputs, paths.gloves))\nmodel_surgical = pd.read_csv(os.path.join(paths.outputs, paths.surgical_mask))\nmodel_gown = pd.read_csv(os.path.join(paths.outputs, paths.gown))\nmodel_n95 = pd.read_csv(os.path.join(paths.outputs, paths.n95_mask))\npaper_tab6 = pd.read_csv(os.path.join(paths.paper, paths.tab6))"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#function-to-compare-tables",
    "href": "reproduction/scripts/reproduction.html#function-to-compare-tables",
    "title": "Reproduction",
    "section": "Function to compare tables",
    "text": "Function to compare tables\n\ndef compare_tables(model_tab, paper_tab):\n    '''\n    Combine the model and paper tables into single dataframe with a diff column\n\n    Parameters:\n    -----------\n    model_tab : dataframe\n        Raw output from model\n    paper_tab : dataframe\n        Reformatted table from supplementary materials\n    '''\n    # Merge the dataframes\n    comp = pd.merge(\n        model_tab.rename(columns={'prop_infected': 'prop_infected_model'}),\n        paper_tab.rename(columns={'prop_infected': 'prop_infected_paper'}))\n\n    # Calculate difference\n    comp['diff'] = abs(comp['prop_infected_model'] -\n                       comp['prop_infected_paper'])\n\n    return comp"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#examine-differences-in-supplementary-tables",
    "href": "reproduction/scripts/reproduction.html#examine-differences-in-supplementary-tables",
    "title": "Reproduction",
    "section": "Examine differences in supplementary tables",
    "text": "Examine differences in supplementary tables\n\nSupplementary table 2\n\n# Get table 2 and save to csv\nmodel_tab2 = model_base15[model_base15['end_of_day'].isin([7, 14, 21])]\nmodel_tab2.to_csv(os.path.join(paths.outputs, paths.tab2), index=False)\n\n\n# Combine model results alongside results from paper\nt2_comp = compare_tables(model_tab2, paper_tab2)\n\n# Descriptive statistics for absolute difference in results\nprint(t2_comp['diff'].describe())\n\n# Extracting instances where absolute difference is more than 0.05\ndisplay(t2_comp[t2_comp['diff'] &gt; 0.05])\n\ncount    420.000000\nmean       0.008405\nstd        0.017549\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n\n\n\nstrength\nstaff_change\nstaff_per_shift\nshifts_per_day\nend_of_day\nprop_infected_model\nprop_infected_paper\ndiff\n\n\n\n\n24\n2\n7\n5\n1\n7\n0.40\n0.30\n0.10\n\n\n36\n2\n14\n5\n1\n7\n0.30\n0.40\n0.10\n\n\n84\n4\n7\n5\n1\n7\n0.15\n0.20\n0.05\n\n\n96\n4\n14\n5\n1\n7\n0.15\n0.20\n0.05\n\n\n97\n4\n14\n5\n2\n7\n0.15\n0.20\n0.05\n\n\n98\n4\n14\n5\n3\n7\n0.15\n0.20\n0.05\n\n\n109\n4\n21\n5\n2\n7\n0.15\n0.20\n0.05\n\n\n204\n2\n7\n5\n1\n14\n0.40\n0.30\n0.10\n\n\n243\n4\n1\n10\n1\n14\n0.12\n0.17\n0.05\n\n\n248\n4\n1\n20\n3\n14\n0.44\n0.53\n0.09\n\n\n250\n4\n1\n30\n2\n14\n0.60\n0.66\n0.06\n\n\n264\n4\n7\n5\n1\n14\n0.15\n0.20\n0.05\n\n\n311\n6\n1\n30\n3\n14\n0.29\n0.34\n0.05\n\n\n422\n4\n1\n5\n3\n21\n0.23\n0.30\n0.07\n\n\n423\n4\n1\n10\n1\n21\n0.25\n0.34\n0.09\n\n\n424\n4\n1\n10\n2\n21\n0.34\n0.41\n0.07\n\n\n435\n4\n3\n10\n1\n21\n0.35\n0.45\n0.10\n\n\n436\n4\n3\n10\n2\n21\n0.40\n0.47\n0.07\n\n\n489\n6\n1\n30\n1\n21\n0.44\n0.50\n0.06\n\n\n\n\n\n\n\n\n\nSupplementary table 3\n\n# Get table 3 and save to csv\nmodel_tab3 = model_base5[model_base5['end_of_day'].isin([7, 14, 21])]\nmodel_tab3.to_csv(os.path.join(paths.outputs, paths.tab3), index=False)\n\n\n# Combine tables\nt3_comp = compare_tables(model_tab3, paper_tab3)\n\n# Descriptive statistics for absolute difference in results\nprint(t3_comp['diff'].describe())\n\n# Extracting instances where absolute difference is more than 0.05\ndisplay(t3_comp[t3_comp['diff'] &gt; 0.05])\n\ncount    420.000000\nmean       0.009905\nstd        0.017464\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n\n\n\nstrength\nstaff_change\nstaff_per_shift\nshifts_per_day\nend_of_day\nprop_infected_model\nprop_infected_paper\ndiff\n\n\n\n\n24\n2\n7\n5\n1\n7\n0.10\n0.20\n0.10\n\n\n30\n2\n7\n20\n1\n7\n0.15\n0.20\n0.05\n\n\n48\n2\n21\n5\n1\n7\n0.10\n0.20\n0.10\n\n\n192\n2\n3\n5\n1\n14\n0.10\n0.20\n0.10\n\n\n204\n2\n7\n5\n1\n14\n0.10\n0.20\n0.10\n\n\n210\n2\n7\n20\n1\n14\n0.15\n0.20\n0.05\n\n\n216\n2\n14\n5\n1\n14\n0.20\n0.30\n0.10\n\n\n228\n2\n21\n5\n1\n14\n0.20\n0.30\n0.10\n\n\n396\n2\n14\n5\n1\n21\n0.20\n0.30\n0.10\n\n\n469\n4\n21\n5\n2\n21\n0.20\n0.15\n0.05\n\n\n\n\n\n\n\n\n\nSupplementary table 4\n\n# Get table 4 and save to csv\nmodel_tab4 = model_base30[model_base30['end_of_day'].isin([7, 14, 21])]\nmodel_tab4.to_csv(os.path.join(paths.outputs, paths.tab4), index=False)\n\n\n# Combine tables\nt4_comp = compare_tables(model_tab4, paper_tab4)\n\n# Descriptive statistics for absolute difference in results\nprint(t4_comp['diff'].describe())\n\n# Extracting instances where absolute difference is more than 0.05\ndisplay(t4_comp[t4_comp['diff'] &gt; 0.05])\n\ncount    420.000000\nmean       0.004762\nstd        0.012765\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.000000\nmax        0.120000\nName: diff, dtype: float64\n\n\n\n\n\n\n\n\n\nstrength\nstaff_change\nstaff_per_shift\nshifts_per_day\nend_of_day\nprop_infected_model\nprop_infected_paper\ndiff\n\n\n\n\n12\n2\n3\n5\n1\n7\n0.40\n0.30\n0.10\n\n\n74\n4\n3\n5\n3\n7\n0.20\n0.15\n0.05\n\n\n257\n4\n3\n10\n3\n14\n0.50\n0.55\n0.05\n\n\n421\n4\n1\n5\n2\n21\n0.53\n0.65\n0.12\n\n\n422\n4\n1\n5\n3\n21\n0.60\n0.65\n0.05\n\n\n\n\n\n\n\n\n\nSupplementary table 5\n\n# Get table 5 and save to csv\nmodel_tab5 = model_norest[model_norest['end_of_day'].isin([7, 14, 21])]\nmodel_tab5.to_csv(os.path.join(paths.outputs, paths.tab5), index=False)\n\n\n# Combine tables\nt5_comp = compare_tables(model_tab5, paper_tab5)\n\n# Descriptive statistics for absolute difference in results\nprint(t5_comp['diff'].describe())\n\n# Extracting instances where absolute difference is more than 0.05\ndisplay(t5_comp[t5_comp['diff'] &gt; 0.05])\n\ncount    180.000000\nmean       0.012056\nstd        0.022614\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.020000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n\n\n\nstrength\nstaff_change\nstaff_per_shift\nshifts_per_day\nend_of_day\nprop_infected_model\nprop_infected_paper\ndiff\n\n\n\n\n12\n2\n14\n5\n1\n7\n0.40\n0.30\n0.10\n\n\n16\n2\n21\n5\n1\n7\n0.30\n0.40\n0.10\n\n\n60\n2\n1\n5\n1\n14\n0.40\n0.50\n0.10\n\n\n68\n2\n7\n5\n1\n14\n0.60\n0.50\n0.10\n\n\n120\n2\n1\n5\n1\n21\n0.70\n0.80\n0.10\n\n\n124\n2\n3\n5\n1\n21\n0.70\n0.80\n0.10\n\n\n140\n4\n1\n5\n1\n21\n0.15\n0.20\n0.05\n\n\n141\n4\n1\n10\n1\n21\n0.29\n0.39\n0.10\n\n\n162\n6\n1\n20\n1\n21\n0.29\n0.34\n0.05\n\n\n\n\n\n\n\n\n\nSupplementary table 6\n\n# Add label to each dataframe\nmodel_contact['workplace_measure'] = 'Social distancing'\nmodel_gloves['workplace_measure'] = 'Gloves'\nmodel_surgical['workplace_measure'] = 'Surgical mask'\nmodel_gown['workplace_measure'] = 'Gown'\nmodel_n95['workplace_measure'] = 'N95 mask'\n\n# Combine results into a single table and filter to day 14\nmodel_tab6 = pd.concat([\n    model_contact, model_gloves, model_surgical, model_gown, model_n95])\nmodel_tab6 = model_tab6[model_tab6['end_of_day'] == 14]\n\n# Save to csv\nmodel_tab6.to_csv(os.path.join(paths.outputs, paths.tab6), index=False)\n\n\n# Confirming how many are NaN, so we are sure the combined table includes all\n# the relevant counts being compared\npaper_tab6['prop_infected'].isnull().value_counts()\n\nFalse    700\nTrue     200\nName: prop_infected, dtype: int64\n\n\n\n# Combine tables\nt6_comp = compare_tables(model_tab6, paper_tab6)\n\n# Descriptive statistics for absolute difference in results\nprint(t6_comp['diff'].describe())\n\n# Extracting instances where absolute difference is more than 0.05\ndisplay(t6_comp[t6_comp['diff'] &gt; 0.05])\n\ncount    700.000000\nmean       0.006214\nstd        0.011161\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.050000\nName: diff, dtype: float64\n\n\n\n\n\n\n\n\n\nstrength\nstaff_change\nstaff_per_shift\nshifts_per_day\nend_of_day\nprop_infected_model\nworkplace_measure\nprop_infected_paper\ndiff\n\n\n\n\n71\n4\n1\n30\n3\n14\n0.18\nSocial distancing\n0.23\n0.05\n\n\n96\n4\n14\n5\n1\n14\n0.15\nSocial distancing\n0.20\n0.05\n\n\n97\n4\n14\n5\n2\n14\n0.15\nSocial distancing\n0.20\n0.05\n\n\n98\n4\n14\n5\n3\n14\n0.20\nSocial distancing\n0.15\n0.05\n\n\n183\n2\n1\n10\n1\n14\n0.20\nGloves\n0.15\n0.05\n\n\n591\n2\n21\n10\n1\n14\n0.15\nGown\n0.20\n0.05"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#figures",
    "href": "reproduction/scripts/reproduction.html#figures",
    "title": "Reproduction",
    "section": "Figures",
    "text": "Figures\nDefine function to create the subplots\n\ndef plot_fig(fig_dict_list, ax, letter, title,\n             ylabel='Proportion of staff infected', legend=True,\n             ytick_freq=0.2):\n    '''\n    Create one of the subplots from the article's figures.\n\n    Parameters:\n    -----------\n    fig_dict_list : list\n        List of dictionaries with parameters to filter dataframe by and for\n        formatting the figure\n    ax : axes object\n        To create the plot on\n    letter : string\n        Letter of subplot (e.g. '(a)', '(b)')\n    title : string\n        Title for the subplot\n    ylabel : string\n        Title for Y axis\n    legend : boolean\n        Whether to include a figure legend for that subplot\n    ytick_freq : number\n        Frequency of Y axis ticks\n    '''\n    # Create each of the line plots\n    for fig_dict in fig_dict_list:\n\n        # Get the filters for the dataframe\n        filt = {key: fig_dict[key] for key in [\n            'shifts_per_day', 'staff_per_shift', 'strength', 'staff_change']}\n\n        # Get subset of dataframe meeting the conditions\n        query = ' & '.join([f\"{col} == {val}\" for col, val in filt.items()])\n        subset = fig_dict['df'].query(query)\n\n        # Reformat so ready to plot\n        to_plot = subset.set_index('end_of_day')['prop_infected']\n\n        # Plot on ax\n        ax.plot(to_plot, label=fig_dict['label'], color=fig_dict['color'],\n                linestyle=fig_dict['linestyle'], linewidth=3)\n\n    # Formatting the figure to match the paper\n    ax.set_title(title)\n    ax.set_xlabel('Day')\n    ax.set_xticks(np.arange(0, 21, 5))\n    ax.set_ylabel(ylabel)\n    ax.set_yticks(np.arange(0, 1.1, ytick_freq))\n    ax.set_ylim(0, 1)\n    if legend == True:\n        ax.legend(loc='upper left')\n    ax.annotate(letter, xy=(-0.15, 1.1), xycoords='axes fraction')\n    ax.grid()\n\n\nFigure 2\nSet out parameters for each of the lines\n\nfig2a_black = {\n    'shifts_per_day': 1,\n    'staff_per_shift': 30,\n    'strength': 2,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '2 x 30 staff/shift',\n    'color': 'black',\n    'linestyle': '-'\n}\n\nfig2a_green = {\n    'shifts_per_day': 1,\n    'staff_per_shift': 10,\n    'strength': 6,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '6 x 10 staff/shift',\n    'color': '#94B454',\n    'linestyle': '--'\n}\n\nfig2b_black = {\n    'shifts_per_day': 2,\n    'staff_per_shift': 30,\n    'strength': 4,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '4 x 30 staff/shift',\n    'color': 'black',\n    'linestyle': '-'\n}\n\nfig2b_green = {\n    'shifts_per_day': 2,\n    'staff_per_shift': 20,\n    'strength': 6,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '6 x 20 staff/shift',\n    'color': '#94B454',\n    'linestyle': '--'\n}\n\nfig2c_black = {\n    'shifts_per_day': 3,\n    'staff_per_shift': 30,\n    'strength': 4,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '4 x 30 staff/shift',\n    'color': 'black',\n    'linestyle': '-'\n}\n\nfig2c_green = {\n    'shifts_per_day': 3,\n    'staff_per_shift': 20,\n    'strength': 6,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '6 x 20 staff/shift',\n    'color': '#94B454',\n    'linestyle': '--'\n}\n\nfig2d_blue = {\n    'shifts_per_day': 2,\n    'staff_per_shift': 30,\n    'strength': 4,\n    'staff_change': 1,\n    'df': model_base5,\n    'label': '5%',\n    'color': '#0D5BB7',\n    'linestyle': ':'\n}\n\nfig2d_black = {\n    'shifts_per_day': 2,\n    'staff_per_shift': 30,\n    'strength': 4,\n    'staff_change': 1,\n    'df': model_base15,\n    'label': '15%',\n    'color': 'black',\n    'linestyle': '-'\n}\n\nfig2d_red = {\n    'shifts_per_day': 2,\n    'staff_per_shift': 30,\n    'strength': 4,\n    'staff_change': 1,\n    'df': model_base30,\n    'label': '3%',\n    'color': '#C14C46',\n    'linestyle': '--'\n}\n\nCreate the figure\n\n# Set up number of subplots and figure size\nfig, ax = plt.subplots(2, 2, figsize=(8, 6))\n\n# Create the subplots\nplot_fig([fig2a_black, fig2a_green], ax[0,0], letter='(a)',\n          title='1 shift per day\\nTotal staff = 60')\nplot_fig([fig2b_black, fig2b_green], ax[0,1], letter='(b)',\n          title='2 shifts per day\\nTotal staff = 120')\nplot_fig([fig2c_black, fig2c_green], ax[1,0], letter='(c)',\n          title='3 shifts per day\\nTotal staff = 120')\nplot_fig([fig2d_blue, fig2d_black, fig2d_red], ax[1,1], letter='(d)',\n          title='2 shifts per day\\nTotal staff = 4 x 30 staff/shift')\n\n# Prevent overlap between subplots\nfig.tight_layout()\n\n# Save the figure\nplt.savefig(os.path.join(paths.outputs, paths.fig2))\n\n# Display the figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigure 3\nFormatting for each of the four lines (which are the same for each subplot)\n\nfig3_lines = [\n    # Black line\n    {\n        'staff_per_shift': 5,\n        'label': '5 staff/shift',\n        'color': 'black',\n        'linestyle': '-'\n    },\n    # Green line\n    {\n        'staff_per_shift': 10,\n        'label': '10 staff/shift',\n        'color': '#94B454',\n        'linestyle': '--'\n    },\n    # Purple line\n    {\n        'staff_per_shift': 20,\n        'label': '20 staff/shift',\n        'color': '#7F619D',\n        'linestyle': ':'\n    },\n    # Red line\n    {\n        'staff_per_shift': 30,\n        'label': '30 staff/shift',\n        'color': '#C14C46',\n        'linestyle': '-'\n    }\n]\n\nSet default parameters for each subplot\n\nall_fig3 = {\n    'staff_change': 1,\n    'df': model_base15\n}\n\n# These are default for Figure 3 and 4, so we reuse them below\nall_fig34a = {\n    'shifts_per_day': 1,\n    'strength': 4\n}\n\nall_fig34b = {\n    'shifts_per_day': 1,\n    'strength': 6\n}\n\nall_fig34c = {\n    'shifts_per_day': 2,\n    'strength': 4\n}\n\nall_fig34d = {\n    'shifts_per_day': 2,\n    'strength': 6\n}\n\nall_fig34e = {\n    'shifts_per_day': 3,\n    'strength': 4\n}\n\nall_fig34f = {\n    'shifts_per_day': 3,\n    'strength': 6\n}\n\nCombine dictionaries to get conditions for plots\n\nfig3a = [{**all_fig3, **all_fig34a, **x} for x in fig3_lines]\nfig3b = [{**all_fig3, **all_fig34b, **x} for x in fig3_lines]\nfig3c = [{**all_fig3, **all_fig34c, **x} for x in fig3_lines]\nfig3d = [{**all_fig3, **all_fig34d, **x} for x in fig3_lines]\nfig3e = [{**all_fig3, **all_fig34e, **x} for x in fig3_lines]\nfig3f = [{**all_fig3, **all_fig34f, **x} for x in fig3_lines]\n\nCreate the plot\n\n# Set up number of subplots and figure size\nfig, ax = plt.subplots(3, 2, figsize=(8, 9))\n\nplot_fig(fig3a, ax[0,0], title='Total staff = 4 x no. staff/shift',\n         letter='(a)',\n         ylabel='$\\\\bf{1\\ shift\\ per\\ day}$\\nProportion of staff infected')\n\nplot_fig(fig3b, ax[0,1], letter='(b)',\n         title='Total staff = 6 x no. staff/shift', legend=False)\n\nplot_fig(fig3c, ax[1,0], letter='(c)', title='',\n         ylabel='$\\\\bf{2\\ shifts\\ per\\ day}$\\nProportion of staff infected',\n         legend=False)\n\nplot_fig(fig3d, ax[1,1], letter='(d)', title='', legend=False)\n\nplot_fig(fig3e, ax[2,0], letter='(e)', title='',\n         ylabel='$\\\\bf{3\\ shifts\\ per\\ day}$\\nProportion of staff infected',\n         legend=False)\n\nplot_fig(fig3f, ax[2,1], letter='(f)', title='', legend=False)\n\n# Prevent overlap between subplots\nfig.tight_layout()\n\n# Save the figure\nplt.savefig(os.path.join(paths.outputs, paths.fig3))\n\n# Display the figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigure 4\nFormatting for each of the five lines (which are the same for each subplot)\n\nfig4_lines = [\n    # Black line\n    {\n        'staff_change': 1,\n        'label': 'Shift change after 1 day',\n        'color': 'black',\n        'linestyle': '-'\n    },\n    # Grey line\n    {\n        'staff_change': 3,\n        'label': 'Shift change after 3 days',\n        'color': '#7F7F7F',\n        'linestyle': '--'\n    },\n    # Blue line\n    {\n        'staff_change': 7,\n        'label': 'Shift change after 7 days',\n        'color': '#0054B4',\n        'linestyle': ':'\n    },\n    # Red line\n    {\n        'staff_change': 14,\n        'label': 'Shift change after 14 days',\n        'color': '#F20000',\n        'linestyle': '-'\n    },\n    # Green line\n    {\n        'staff_change': 21,\n        'label': 'Shift change after 21 days',\n        'color': '#9BB05C',\n        'linestyle': '--'\n    }\n]\n\nSet default parameters for subplots (using some defined above, as same as Figure 3 for some)\n\nall_fig4 = {\n    'staff_per_shift': 20,\n    'df': model_base15\n}\n\nCombine dictionaries to get conditions for plots\n\nfig4a = [{**all_fig4, **all_fig34a, **x} for x in fig4_lines]\nfig4b = [{**all_fig4, **all_fig34b, **x} for x in fig4_lines]\nfig4c = [{**all_fig4, **all_fig34c, **x} for x in fig4_lines]\nfig4d = [{**all_fig4, **all_fig34d, **x} for x in fig4_lines]\nfig4e = [{**all_fig4, **all_fig34e, **x} for x in fig4_lines]\nfig4f = [{**all_fig4, **all_fig34f, **x} for x in fig4_lines]\n\nCreate the plot\n\n# Set up number of subplots and figure size\nfig, ax = plt.subplots(3, 2, figsize=(8, 9))\n\nplot_fig(fig4a, ax[0,0], letter='(a)',\n         title='Total staff = 4 x no. staff/shift',\n         ylabel='$\\\\bf{1\\ shift\\ per\\ day}$\\nProportion of staff infected',\n         legend=False)\n\nplot_fig(fig4b, ax[0,1], letter='(b)',\n         title='Total staff = 6 x no. staff/shift', legend=True)\n\nplot_fig(fig4c, ax[1,0], letter='(c)', title='',\n         ylabel='$\\\\bf{2\\ shifts\\ per\\ day}$\\nProportion of staff infected',\n         legend=False)\n\nplot_fig(fig4d, ax[1,1], letter='(d)', title='', legend=False)\n\nplot_fig(fig4e, ax[2,0], letter='(e)', title='',\n         ylabel='$\\\\bf{3\\ shifts\\ per\\ day}$\\nProportion of staff infected',\n         legend=False)\n\nplot_fig(fig4f, ax[2,1], letter='(f)', title='', legend=False)\n\n# Prevent overlap between subplots\nfig.tight_layout()\n\n# Save the figure\nplt.savefig(os.path.join(paths.outputs, paths.fig4))\n\n# Display the figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigure 5\nSet default parameters for all lines\n\nall_fig5 = {\n    'shifts_per_day': 1,\n    'staff_per_shift': 30,\n    'strength': 2,\n    'staff_change': 1\n}\n\nThen set specific parameters for each line, and combine with the default parameters\n\nfig5a_black = {\n    **all_fig5,\n    **{\n        'df': model_base15,\n        'label': 'Split team',\n        'color': 'black',\n        'linestyle': '-'\n    }\n}\n\nfig5a_green = {\n    **all_fig5,\n    **{\n        'df': model_contact,\n        'label': 'Split team with social distancing',\n        'color': '#008E27',\n        'linestyle': '--'\n    }\n}\n\nfig5a_blue = {\n    **all_fig5,\n    **{\n        'df': model_norest,\n        'label': 'Random roster assignment',\n        'color': '#0054B4',\n        'linestyle': ':'\n    }\n}\n\nfig5b_black = {\n    **all_fig5,\n    **{\n        'df': model_base15,\n        'label': 'Baseline',\n        'color': 'black',\n        'linestyle': '-'\n    }\n}\n\nfig5b_green = {\n    **all_fig5,\n    **{\n        'df': model_gloves,\n        'label': 'Wearing gloves',\n        'color': '#008E27',\n        'linestyle': '--'\n    }\n}\n\nfig5b_blue = {\n    **all_fig5,\n    **{\n        'df': model_surgical,\n        'label': 'Wearing surgical mask',\n        'color': '#0054B4',\n        'linestyle': ':'\n    }\n}\n\nfig5b_grey = {\n    **all_fig5,\n    **{\n        'df': model_gown,\n        'label': 'Wearing gown',\n        'color': '#7F7F7F',\n        'linestyle': '--'\n    }\n}\n\nfig5b_red = {\n    **all_fig5,\n    **{\n        'df': model_n95,\n        'label': 'Wearing N95 mask',\n        'color': '#E71111',\n        'linestyle': '-'\n    }\n}\n\n\n# Set up number of subplots and figure size\nfig, ax = plt.subplots(2, 1, figsize=(6, 9))\n\nplot_fig([fig5a_black, fig5a_green, fig5a_blue], ax[0], letter='(a)',\n         title='', legend=True, ytick_freq=0.1)\n\nplot_fig([fig5b_black, fig5b_green, fig5b_blue, fig5b_grey, fig5b_red], ax[1],\n         letter='(b)', title='', legend=True, ytick_freq=0.1)\n\n# Prevent overlap between subplots\nfig.tight_layout()\n\n# Save the figure\nplt.savefig(os.path.join(paths.outputs, paths.fig5))\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "reproduction/scripts/reproduction.html#time-elapsed",
    "href": "reproduction/scripts/reproduction.html#time-elapsed",
    "title": "Reproduction",
    "section": "Time elapsed",
    "text": "Time elapsed\n\nif run_model:\n    # Find run time in seconds\n    end = time.time()\n    runtime = round(end-start)\n\n    # Display converted to minutes and seconds\n    print(f'Notebook run time: {runtime//60}m {runtime%60}s')"
  },
  {
    "objectID": "quarto_site/study_publication.html",
    "href": "quarto_site/study_publication.html",
    "title": "Publication",
    "section": "",
    "text": "Lim et al. (2020)"
  },
  {
    "objectID": "quarto_site/study_publication.html#code",
    "href": "quarto_site/study_publication.html#code",
    "title": "Publication",
    "section": "Code",
    "text": "Code\nView at: https://github.com/pythonhealthdatascience/stars-reproduce-lim-2020/tree/main/original_study/COVID-roster-simulation\nCode from: https://github.com/chaose5/COVID-roster-simulation"
  },
  {
    "objectID": "quarto_site/study_publication.html#journal-article",
    "href": "quarto_site/study_publication.html#journal-article",
    "title": "Publication",
    "section": "Journal article",
    "text": "Journal article\nArticle with publisher: https://doi.org/10.1016/j.clinbiochem.2020.09.003\nArticle on PMC: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7486214/"
  },
  {
    "objectID": "quarto_site/study_publication.html#supplementary-materials",
    "href": "quarto_site/study_publication.html#supplementary-materials",
    "title": "Publication",
    "section": "Supplementary materials",
    "text": "Supplementary materials\nSupplementary materials 1:\n\n\nSupplementary materials 2:"
  },
  {
    "objectID": "original_study/reformat_tables.html",
    "href": "original_study/reformat_tables.html",
    "title": "Reformat the tables",
    "section": "",
    "text": "This notebook converts the provided results tables from wide to long format, and to remove the “sharing” of cells, so that each row contains all the information needed to identify it.\nThis is to make it easier for me to use and compare against these results during the reproduction."
  },
  {
    "objectID": "original_study/reformat_tables.html#set-up",
    "href": "original_study/reformat_tables.html#set-up",
    "title": "Reformat the tables",
    "section": "Set up",
    "text": "Set up\n\n# Import required libraries\nimport numpy as np\nimport pandas as pd\n\n\n# Create list of files\nfiles = [f'supp_tab{i}.csv' for i in range(2, 7)]\nfiles\n\n['supp_tab2.csv',\n 'supp_tab3.csv',\n 'supp_tab4.csv',\n 'supp_tab5.csv',\n 'supp_tab6.csv']"
  },
  {
    "objectID": "original_study/reformat_tables.html#function-to-reformat-tables",
    "href": "original_study/reformat_tables.html#function-to-reformat-tables",
    "title": "Reformat the tables",
    "section": "Function to reformat tables",
    "text": "Function to reformat tables\n\ndef reformat_table(filename):\n    '''\n    Converts the supplementary tables from Lim et al. into a useable format for\n    processing and comparison against.\n\n    Most of these require the same processing, with the exception of table 6,\n    which has workplace measures instead of end of day categories\n\n    Parameters:\n    ----------\n    filename : string\n        Name of file containing the table to be reformatted\n    '''\n    tab = pd.read_csv(filename, header=None)\n\n    # Rename second column, which contains number of staff per shift\n    tab.rename(columns={tab.columns[2]: 'staff_per_shift'}, inplace=True)\n\n    # Preview head of dataframe\n    display(tab.head())\n\n    # Get name of column depending on whether this is table 6 or not\n    if filename == 'supp_tab6.csv':\n        column = 'workplace_measure'\n    else:\n        column = 'end_of_day'\n\n    # Make copies of the first column, which we will extract end of day and\n    # number of shifts from\n    tab.insert(loc=1, column=column, value=tab[0])\n    tab.insert(loc=2, column='shifts_per_day', value=tab[0])\n\n    # If this is supplementary table 6, do processing for workplace measures\n    if filename == 'supp_tab6.csv':\n        # Just keep rows that list the protective workplace measure used, and\n        # then fill rows based on value above\n        measures = ['Social distancing', 'Gloves',\n                    'Surgical mask', 'Gown', 'N95 mask']\n        tab.loc[~tab['workplace_measure'].isin(measures),\n                'workplace_measure'] = np.nan\n        tab['workplace_measure'] = tab['workplace_measure'].ffill()\n    # Otherwise, do processing for end of day\n    else:\n        # Keep the 'End of Day' rows, then remove that string, and populate NaN\n        # rows with the end of day int above them\n        tab['end_of_day'] = np.where(\n            tab['end_of_day'].str.contains('End of Day'),\n            tab['end_of_day'],\n            np.nan)\n        tab['end_of_day'] = tab['end_of_day'].str.replace(\n            'End of Day ', '').ffill()\n\n    # Set the first instance to NaN (as it is not on row with values)\n    tab.loc[1, column] = np.nan\n\n    # Repeat 'End of Day' process, but this time for 'No. of shift/day'\n    # Get the rows where it contains string 'No. of shift/day', keeping int\n    shift_a = pd.Series(np.where(\n        tab['shifts_per_day'].str.contains('No. of shift'),\n        tab['shifts_per_day'],\n        np.nan)).str.replace('No. of shift/ day', '')\n    # Get the rows where number of shifts is just given by an integer\n    shift_b = pd.to_numeric(tab['shifts_per_day'], errors='coerce')\n    # Combine into a single column, populate NaN with value from above, and\n    # replace column in dataframe\n    tab['shifts_per_day'] = pd.to_numeric(shift_a.fillna(shift_b)).ffill()\n\n    # Remove columns with unnecessary information\n    tab.drop(tab.columns[0], axis=1, inplace=True)\n    tab.drop(tab.columns[2], axis=1, inplace=True)\n\n    # Drop row where all of the results are NaN\n    tab = tab[tab[tab.columns[3:18]].notna().any(axis=1)]\n\n    # Fill value of staff strength based on column to left\n    tab.loc[0] = tab.loc[0].infer_objects(copy=False).ffill()\n\n    # The first two rows contain the total number of staff strength and the\n    # frequency of staff change in days. We want to make those into the headers.\n    # We add a prefix to the numbers, then combine them to make column headers\n    names_a = tab.loc[0].apply(\n        lambda x: f'strength_{int(x)}_' if ~np.isnan(x) else x)\n    names_b = tab.loc[1].apply(\n        lambda x: f'staff_change_{int(x)}' if ~np.isnan(x) else x)\n    tab.columns = list(tab.columns[0:3]) + list((names_a + names_b).dropna())\n\n    # Drop the first two rows (now used for column headers)\n    tab.drop([0, 1], inplace=True)\n\n    # Transform from wide to long\n    reformat = pd.melt(\n        tab, id_vars=[column, 'shifts_per_day', 'staff_per_shift'],\n        var_name='var', value_name='prop_infected')\n\n    # Seperate out strength and staff change\n    reformat[['strength', 'staff_change']] = reformat['var'].str.extract(\n        r'strength_(\\d+)_staff_change_(\\d+)')\n    reformat.drop(columns=['var'], inplace=True)\n\n    # Move the proportion infected column to the end\n    proportion = reformat.pop('prop_infected')\n    reformat['prop_infected'] = proportion\n\n    # Make sure all columns (except workplace_measure) are numeric\n    cols = [i for i in reformat.columns if i not in ['workplace_measure']]\n    for col in cols:\n        reformat[col] = pd.to_numeric(reformat[col])\n\n    # Sort in order that makes it easy to compare against original format\n    reformat.sort_values(by=[column, 'shifts_per_day', 'staff_per_shift',\n                             'strength', 'staff_change'], inplace=True)\n\n    # Preview head of dataframe\n    display(reformat.head(10))\n\n    # Save to csv\n    reformat.to_csv(filename.replace('.csv', '_reformat.csv'), index=False)"
  },
  {
    "objectID": "original_study/reformat_tables.html#apply-the-function",
    "href": "original_study/reformat_tables.html#apply-the-function",
    "title": "Reformat the tables",
    "section": "Apply the function",
    "text": "Apply the function\n\nfor f in files:\n    reformat_table(f)\n\n\n\n\n\n\n\n\n0\n1\nstaff_per_shift\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\nTotal number of staff strength\nNaN\nNaN\n2.00\nNaN\nNaN\nNaN\nNaN\n4.00\nNaN\nNaN\nNaN\nNaN\n6.00\nNaN\nNaN\nNaN\nNaN\n\n\n1\nEnd of Day 7\nFreq. of staff change, days\nNaN\n1.00\n3.00\n7.0\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n\n\n2\nNo. of shift/ day 1\nNumber of staff per shift\n5.0\n0.20\n0.20\n0.3\n0.40\n0.30\n0.10\n0.10\n0.20\n0.20\n0.15\n0.03\n0.05\n0.13\n0.10\n0.13\n\n\n3\nNaN\nNaN\n10.0\n0.20\n0.25\n0.4\n0.43\n0.45\n0.07\n0.10\n0.20\n0.20\n0.20\n0.03\n0.05\n0.15\n0.13\n0.15\n\n\n4\nNaN\nNaN\n20.0\n0.31\n0.33\n0.5\n0.50\n0.50\n0.07\n0.11\n0.25\n0.25\n0.25\n0.03\n0.08\n0.17\n0.17\n0.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.20\n\n\n36\n7\n1.0\n5.0\n2\n3\n0.20\n\n\n72\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n108\n7\n1.0\n5.0\n2\n14\n0.40\n\n\n144\n7\n1.0\n5.0\n2\n21\n0.30\n\n\n180\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n216\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n252\n7\n1.0\n5.0\n4\n7\n0.20\n\n\n288\n7\n1.0\n5.0\n4\n14\n0.20\n\n\n324\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\nstaff_per_shift\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\nTotal number of staff strength\nNaN\nNaN\n2.00\nNaN\nNaN\nNaN\nNaN\n4.00\nNaN\nNaN\nNaN\nNaN\n6.00\nNaN\nNaN\nNaN\nNaN\n\n\n1\nEnd of Day 7\nFreq. of staff change, days\nNaN\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n\n\n2\nNo. of shift/ day 1\nNumber of staff per shift\n5.0\n0.10\n0.10\n0.20\n0.10\n0.20\n0.05\n0.05\n0.10\n0.05\n0.05\n0.03\n0.03\n0.07\n0.07\n0.03\n\n\n3\nNaN\nNaN\n10.0\n0.10\n0.10\n0.15\n0.12\n0.15\n0.03\n0.03\n0.07\n0.05\n0.07\n0.02\n0.02\n0.03\n0.05\n0.03\n\n\n4\nNaN\nNaN\n20.0\n0.07\n0.07\n0.20\n0.17\n0.17\n0.03\n0.04\n0.07\n0.07\n0.07\n0.02\n0.02\n0.05\n0.05\n0.06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.10\n\n\n36\n7\n1.0\n5.0\n2\n3\n0.10\n\n\n72\n7\n1.0\n5.0\n2\n7\n0.20\n\n\n108\n7\n1.0\n5.0\n2\n14\n0.10\n\n\n144\n7\n1.0\n5.0\n2\n21\n0.20\n\n\n180\n7\n1.0\n5.0\n4\n1\n0.05\n\n\n216\n7\n1.0\n5.0\n4\n3\n0.05\n\n\n252\n7\n1.0\n5.0\n4\n7\n0.10\n\n\n288\n7\n1.0\n5.0\n4\n14\n0.05\n\n\n324\n7\n1.0\n5.0\n4\n21\n0.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\nstaff_per_shift\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\nTotal number of staff strength\nNaN\nNaN\n2.00\nNaN\nNaN\nNaN\nNaN\n4.00\nNaN\nNaN\nNaN\nNaN\n6.00\nNaN\nNaN\nNaN\nNaN\n\n\n1\nEnd of Day 7\nFreq. of staff change, days\nNaN\n1.00\n3.00\n7.0\n14.0\n21.0\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n\n\n2\nNo. of shift/ day 1\nNumber of staff per shift\n5.0\n0.40\n0.30\n0.5\n0.5\n0.5\n0.10\n0.20\n0.25\n0.25\n0.25\n0.07\n0.10\n0.17\n0.17\n0.17\n\n\n3\nNaN\nNaN\n10.0\n0.43\n0.45\n0.5\n0.5\n0.5\n0.12\n0.21\n0.25\n0.25\n0.25\n0.07\n0.12\n0.17\n0.17\n0.17\n\n\n4\nNaN\nNaN\n20.0\n0.50\n0.50\n0.5\n0.5\n0.5\n0.25\n0.30\n0.25\n0.25\n0.25\n0.10\n0.19\n0.17\n0.17\n0.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.40\n\n\n36\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n72\n7\n1.0\n5.0\n2\n7\n0.50\n\n\n108\n7\n1.0\n5.0\n2\n14\n0.50\n\n\n144\n7\n1.0\n5.0\n2\n21\n0.50\n\n\n180\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n216\n7\n1.0\n5.0\n4\n3\n0.20\n\n\n252\n7\n1.0\n5.0\n4\n7\n0.25\n\n\n288\n7\n1.0\n5.0\n4\n14\n0.25\n\n\n324\n7\n1.0\n5.0\n4\n21\n0.25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\nstaff_per_shift\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\nTotal number of staff strength\nNaN\nNaN\n2.00\nNaN\nNaN\nNaN\nNaN\n4.00\nNaN\nNaN\nNaN\nNaN\n6.00\nNaN\nNaN\nNaN\nNaN\n\n\n1\nEnd of Day 7\nFreq. of staff change, days\nNaN\n1.00\n3.00\n7.0\n14.0\n21.0\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n\n\n2\nNo. of shift/ day 1\nNumber of staff per shift\n5.0\n0.25\n0.30\n0.3\n0.3\n0.4\n0.10\n0.10\n0.15\n0.15\n0.15\n0.03\n0.07\n0.10\n0.13\n0.13\n\n\n3\nNaN\nNaN\n10.0\n0.20\n0.35\n0.4\n0.4\n0.4\n0.07\n0.12\n0.20\n0.23\n0.23\n0.03\n0.08\n0.14\n0.15\n0.15\n\n\n4\nNaN\nNaN\n20.0\n0.47\n0.62\n0.5\n0.5\n0.5\n0.09\n0.28\n0.25\n0.25\n0.25\n0.04\n0.15\n0.17\n0.17\n0.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.25\n\n\n12\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n24\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n36\n7\n1.0\n5.0\n2\n14\n0.30\n\n\n48\n7\n1.0\n5.0\n2\n21\n0.40\n\n\n60\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n72\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n84\n7\n1.0\n5.0\n4\n7\n0.15\n\n\n96\n7\n1.0\n5.0\n4\n14\n0.15\n\n\n108\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\nstaff_per_shift\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\nTotal number of staff strength\nNaN\nNaN\n2.00\nNaN\nNaN\nNaN\nNaN\n4.00\nNaN\nNaN\nNaN\nNaN\n6.00\nNaN\nNaN\nNaN\nNaN\n\n\n1\nSocial distancing\nFreq. of staff change, days\nNaN\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n1.00\n3.00\n7.00\n14.00\n21.00\n\n\n2\nNo. of shift/ day 1\nNumber of staff per shift\n5.0\n0.20\n0.20\n0.20\n0.35\n0.35\n0.05\n0.10\n0.10\n0.20\n0.17\n0.03\n0.03\n0.07\n0.12\n0.13\n\n\n3\nNaN\nNaN\n10.0\n0.20\n0.25\n0.20\n0.45\n0.45\n0.05\n0.07\n0.10\n0.23\n0.20\n0.03\n0.03\n0.08\n0.15\n0.13\n\n\n4\nNaN\nNaN\n20.0\n0.31\n0.38\n0.33\n0.50\n0.50\n0.07\n0.12\n0.16\n0.25\n0.25\n0.03\n0.06\n0.11\n0.17\n0.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n12\nGloves\n1.0\n5.0\n2\n1\n0.20\n\n\n72\nGloves\n1.0\n5.0\n2\n3\n0.20\n\n\n132\nGloves\n1.0\n5.0\n2\n7\n0.20\n\n\n192\nGloves\n1.0\n5.0\n2\n14\n0.30\n\n\n252\nGloves\n1.0\n5.0\n2\n21\n0.30\n\n\n312\nGloves\n1.0\n5.0\n4\n1\n0.05\n\n\n372\nGloves\n1.0\n5.0\n4\n3\n0.05\n\n\n432\nGloves\n1.0\n5.0\n4\n7\n0.10\n\n\n492\nGloves\n1.0\n5.0\n4\n14\n0.15\n\n\n552\nGloves\n1.0\n5.0\n4\n21\n0.15"
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting guidelines",
    "section": "",
    "text": "This page evaluates the extent to which the journal article meets the criteria from two discrete-event simulation study reporting guidelines:"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting guidelines",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nOf the 24 items in the checklist:\n\n16 were met fully (✅)\n2 were partially met (🟡)\n3 were not met (❌)\n3 were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n✅ Fully\nProvided in 1. Introduction -“The International Federation of Clinical Chemistry and Laboratory Medicine (IFCC) has recently formed a Taskforce on COVID-19 to provide guidance to laboratory practitioners in managing this challenge [COVID-19]… A global survey by the Taskforce has then revealed that clinical laboratories have used PPE variably. The laboratories also found it challenging to manage staff rostering, split team arrangement and maintain workplace social distancing (physical distancing)… this simulation study was conducted to explore the relative impact of staff rostering, split team arrangement, social distancing and use of PPE on the potential risk of transmission within the laboratory environment. From the results of this simulation, several recommendations are de- veloped to further assist laboratories in planning their workplace in order to minimize the risk of transmission of SARS-Cov-2 infection.”Lim et al. (2020)\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n✅ Fully\nAll outputs are medians. 2.2 Transmission assumptions - “the median of the proportion of staff infected are recorded”Lim et al. (2020)\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis – Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments – Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation – (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n✅ Fully\nThe various parameters and scenarios of the analysis are described in detail in 2. Material and methods in sections:• 2.1.1 Number of staff per shift and number of shifts• 2.1.2 Overall number of staff accessible to work in the laboratory (i.e. overall staff pool)• 2.1.3 Shift arrangement• 2.1.4 Split team arrangement• 2.3 Secondary attack rate• 2.4 Impact of personal protective equipment• 2.5 Impact of social distancing\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n✅ Fully\nFigure 1Lim et al. (2020)\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n✅ Fully\nDetailed in 2. Material and methods and supported by Figure 1.\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n✅ Fully\nDetailed in 2. Material and methods\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e. scheduling of arrivals/ appointments/ operations/ maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n✅ Fully\nThe only sampling algorithm used in the model is the Poisson distribution for sampling the number of successful contact per infected staff, and this is described in 2.2 Transmission assumptions“Due to the stochastic nature of virus transmission, not all contacts lead to successful virus transmissions. Therefore, the probabilistic factor of p is applied to the average contact rate parameter c in a modified Poisson distribution for the number of “successful” contacts, which refers to contacts that lead to successful viral transmission, per work shift. Mathematically, it is described by: P(k) = (pc)k/k! e-pc where P(k) represents the probability for k successful contact in a work shift, with k being a non-negative integer, p is the probability of transmission while c is the average contact rate (i.e. average number of unique contacts in a shift). From this Poisson distribution k is drawn randomly when susceptible staff are assigned to a shift with at least one infected staff. Subsequently, k staff are randomly drawn from other staff in the same shift to be infected to propagate the infection. Of note, P is a function of R0 (the basic reproduction number), contact rate and length of infection period for an entire population”Lim et al. (2020)\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n✅ Fully\n2. Material and methods - “The entities in the simulation are laboratory staff assigned to work in a particular shift.”Lim et al. (2020)\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n✅ Fully\nThe activity in the model is to be either on or off shift. 2. Material and methods - “In this simple model, each staff can only assume one of the two states, namely staying at home or working in the laboratory. The state of working in the laboratory is further divided into sub-states, representing each work shift, for rosters with more than 1 shift per day.”Lim et al. (2020)\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\nN/A\nThe entity (lab staff) does not require any resources to complete the activity (going on shift). Instead, the model just requires a certain number of entities to be doing the activity.\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g. First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\nN/A\nThere are no queues for activities.\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e. all arrival and exit points of entities. Detail the arrival mechanism (e.g. ‘thinning’ to mimic a non-homogenous Poisson process or balking)\n✅ Fully\nEntities remain in the model for the whole duration.2.2 Transmission assumptions - “Throughout the simulation, it is assumed that the infected staff are not quarantined”Lim et al. (2020)\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:• Interviews with stakeholders,• Samples of routinely collected data,• Prospectively collected samples for the purpose of the simulation study,• Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n✅ Fully\n2.1 Workplace assumptions - “The workplace assumptions are arbitrarily determined to represent a wide range of laboratory scenarios.”4.3 Other observations - “These data on protective effects of PPE are obtained from a meta-analysis of 6 case-control studies related to severe acute respiratory syndrome (SARS) [17], but should be broadly applicable to the current COVID-19 situation.” - although [17] does not have this information, it appears this intends to cite [18] in their references, Jefferson T, Dooley L, Ferroni E, Al-Ansary LA, van Driel ML, Bawazeer GA, Jones MA, Hoffmann TC, Clark J, Beller EM, Glasziou PP, Conly JM. Physical interventions to interrupt or reduce the spread of respiratory viruses. Cochrane Database Syst Rev. 2023 Jan 30;1(1):CD006207. doi: 10.1002/14651858.CD006207.pub6. PMID: 36715243; PMCID: PMC9885521.Lim et al. (2020)\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers.\nN/A\nBased on data sources, assume this to be not applicable.\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:• Base case data• Data use in experimentation, where different from the base case.• Where optimisation or design of experiments has been used, state the range of values that parameters can take.• Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n✅ Fully\nNearly all parameters are included in Table 1The others are described in the article though, e.g. 2.5 Impact of social distancing - “To simulate the effect of workplace social distancing, c is arbitrarily reduced by halve”Lim et al. (2020)\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n✅ Fully\nExtensively details assumptions throughout 2. Material and methods and 4 Discussions\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n❌ Not met\nNot described.\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n✅ Fully\nTime unit is days (1, 2 or 3 shifts per day), and runs for 21 days. Described in article, e.g. 2.2 Transmission assumptions - “duration of simulation (i.e. 21 days)”Lim et al. (2020)\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n✅ Fully\n2.2 Transmission assumptions - “In view of the stochastic nature of virus transmission and roster allocation, simulations with the same parameters are repeated 100 times and the median of the proportion of staff infected are recorded.”Lim et al. (2020)\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g. Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n🟡 Partially\n2.7 Simulation package - “This simulation was performed with codes written in Python 3 on a desktop computer (Intel Core i5 3.5 GHz, 8 GB RAM). Standard libraries such as NumPy and pandas are employed.”Does not mention operating system, or version of the packages used.Lim et al. (2020)\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g. Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n❌ Not met\nNot described in the paper. Know from the code that they used common random numbers without seed control.\n\n\n5.3 Model execution\nState the event processing mechanism used e.g. three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n❌ Not met\nNot described\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n🟡 Partially\n2.7 Simulation package - “This simulation was performed with codes written in Python 3 on a desktop computer (Intel Core i5 3.5 GHz, 8 GB RAM).” Does not mention run timeLim et al. (2020)\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these.\n✅ Fully\n2.7 Simulation package - “The simulation codes used in this study are provided here (https://github.com/chaose5/COVID- roster-simulation) and in the Supplemental Material.”Lim et al. (2020)"
  },
  {
    "objectID": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "href": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "title": "Reporting guidelines",
    "section": "DES checklist derived from ISPOR-SDM",
    "text": "DES checklist derived from ISPOR-SDM\nOf the 18 items in the checklist:\n\n12 were met fully (✅)\n4 were not met (❌)\n2 were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if…\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n…the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n✅ Fully\nMinimising transmission of COVID-19 in laboratories, as in 1 Introduction.\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n…the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n✅ Fully\nThe context here is the laboratories and their strategies to minimise transmission. It describes the current situation, with regards to that. Other description of the laboratories is not felt to be necessary.1 Introduction - “The International Federation of Clinical Chemistry and Laboratory Medicine (IFCC) has recently formed a Taskforce on COVID-19 to provide guidance to aboratory practitioners in managing this challenge. The Task Force has already published biosafety recommendations, which outlined the steps that laboratories operating at biosafety level 1 and level 2 shall or may use to lower the risk of workplace transmission of the virus. These in- cluded the use of personal protective equipment (PPE), temperature and symptom monitoring, split team work arrangements and workplace social distancing. A global survey by the Taskforce has then revealed that clinical laboratories have used PPE variably. The laboratories also found it challenging to manage staff rostering, split team arrangement and maintain workplace social distancing (physical distancing)” Lim et al. (2020)\n\n\n3 Is the model structure described?\n…the model’s conceptual structure was described in the form of either graphical or text presentation.\n✅ Fully\nDetailed in 2. Material and methods and supported by Figure 1.Lim et al. (2020)\n\n\n4 Is the time horizon given?\n…the time period covered by the simulation was reported.\n✅ Fully\n2.2 Transmission assumptions - “duration of simulation (i.e. 21 days)”Lim et al. (2020)\n\n\n5 Are all simulated strategies/scenarios specified?\n…the comparators under test were described in terms of their components, corresponding variations, etc\n✅ Fully\nThe various parameters and scenarios of the analysis are described in detail in 2. Material and methods in sections:• 2.1.1 Number of staff per shift and number of shifts• 2.1.2 Overall number of staff accessible to work in the laboratory (i.e. overall staff pool)• 2.1.3 Shift arrangement• 2.1.4 Split team arrangement• 2.3 Secondary attack rate• 2.4 Impact of personal protective equipment• 2.5 Impact of social distancing\n\n\n6 Is the target population described?\n…the entities simulated and their main attributes were characterized.\n✅ Fully\nPopulation being modelled is laboratory staff and the transmission of COVID-19 between them. Given there would likely be little data on transmission of COVID between staff at the point of publication, it is felt the population is sufficiently, with the main description being the results from a survey of attitudes towards PPE use. 1 Introduction - “A global survey by the Taskforce has then revealed that clinical laboratories have used PPE variably. The laboratories also found it challenging to manage staff rostering, split team arrangement and maintain workplace social distancing (physical distancing)” Lim et al. (2020)\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n…the sources of all data used to inform model inputs were reported.\n✅ Fully\n2.1 Workplace assumptions - “The workplace assumptions are arbitrarily determined to represent a wide range of laboratory scenarios.”4.3 Other observations - “These data on protective effects of PPE are obtained from a meta-analysis of 6 case-control studies related to severe acute respiratory syndrome (SARS) [17], but should be broadly applicable to the current COVID-19 situation.” - although [17] does not have this information, it appears this intends to cite [18] in their references, Jefferson T, Dooley L, Ferroni E, Al-Ansary LA, van Driel ML, Bawazeer GA, Jones MA, Hoffmann TC, Clark J, Beller EM, Glasziou PP, Conly JM. Physical interventions to interrupt or reduce the spread of respiratory viruses. Cochrane Database Syst Rev. 2023 Jan 30;1(1):CD006207. doi: 10.1002/14651858.CD006207.pub6. PMID: 36715243; PMCID: PMC9885521.Lim et al. (2020)\n\n\n8 Are the parameters used to populate model frameworks specified?\n…all relevant parameters fed into model frameworks were disclosed.\n✅ Fully\nNearly all parameters are included in Table 1The others are described in the article though, e.g. 2.5 Impact of social distancing - “To simulate the effect of workplace social distancing, c is arbitrarily reduced by halve”Lim et al. (2020)\n\n\n9 Are model uncertainties discussed?\n…the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n❌ Not met\nJust presents median.\n\n\n10 Are sensitivity analyses performed and reported?\n…the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters’ plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n✅ Fully\nConducts sensitivty analyses, varying the model parameters to explore impact on results, e.g. 3.1 General staff roster arrangement - “The trend of the results of the baseline scenario (15% secondary attach rate) were reproduced in the sensitivity analysis using different sec- ondary attack rates of 5% and 30%.”Lim et al. (2020)\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n…it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n❌ Not met\n-\n\n\n12 Is cross validation performed and reported\n…comparison across similar modeling studies which deal with the same decision problem was undertaken.\n❌ Not met\n-\n\n\n13 Is external validation performed and reported?\n…the modeler(s) examined how well the model’s results match the empirical data of an actual event modeled.\nN/A\nSince this article was submit relatively early in the COVID-19 pandemic, it is reasonably assumed that there may not yet have been empirical data available to compare against, although we note that the paper does not mention whether or not this is the case.\n\n\n14 Is predictive validation performed or attempted?\n…the modeler(s) examined the consistency of a model’s predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\nN/A\nThis is only relevant to forecasting models.\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n…the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n✅ Fully\n2.1 Workplace assumptions - “The workplace assumptions are arbitrarily determined to represent a wide range of laboratory scenarios.”5. Conclusion - “The several broad recommendations are drawn from the results of the simulations. The recommendations are not meant to be pre- scriptive. Each laboratory operates in a unique environment and should tailor their practices to best suit their priorities within the available resources.”Lim et al. (2020)\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n…the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n❌ Not met\n-\n\n\n17 Is the source of funding stated?\n…the sponsorship of the study was indicated.\n✅ Fully\nAcknowledgement - “Sources of support None.”Lim et al. (2020)\n\n\n18 Are model limitations discussed?\n…limitations of the assessed model, especially limitations of interest to decision makers, were discussed.\n✅ Fully\nAssumptions and limitations of the model and study are described in 2. Material and methods and 4 Discussion"
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Journal badges",
    "section": "",
    "text": "This page evaluates the extent to which the author-published research artefacts meet the criteria of badges related to reproducibility from various organisations and journals.\nCaveat: Please note that these criteria are based on available information about each badge online, and that we have likely differences in our procedure (e.g. allowed troubleshooting for execution and reproduction, not under tight time pressure to complete). Moreover, we focus only on reproduction of the discrete-event simulation, and not on other aspects of the article. We cannot guarantee that the badges below would have been awarded in practice by these journals."
  },
  {
    "objectID": "evaluation/badges.html#criteria",
    "href": "evaluation/badges.html#criteria",
    "title": "Journal badges",
    "section": "Criteria",
    "text": "Criteria\n\n\nCode\nfrom IPython.display import display, Markdown\nimport numpy as np\nimport pandas as pd\n\n# Criteria and their definitions\ncriteria = {\n    'archive': 'Stored in a permanent archive that is publicly and openly accessible',\n    'id': 'Has a persistent identifier',\n    'license': 'Includes an open license',\n    'relevant': '''Artefacts are relevant to and contribute to the article's results''',\n    'complete': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'structure': 'Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)',\n    'documentation_sufficient': 'Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)',\n    'documentation_careful': 'Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)',\n    # This criteria is kept seperate to documentation_careful, as it specifically requires a README file\n    'documentation_readme': 'Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript',\n    'execute': 'Scripts can be successfully executed',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n}\n\n# Evaluation for this study\neval = pd.Series({\n    'archive': 0,\n    'id': 0,\n    'license': 0,  # At the point of publication\n    'relevant': 1,\n    'complete': 0,\n    'structure': 0,\n    'documentation_sufficient': 0,\n    'documentation_careful': 0,\n    'documentation_readme': 0,\n    'execute': 1,\n    'regenerated': 1,\n    'hour': 0,\n})\n\n# Get list of criteria met (True/False) overall\neval_list = list(eval)\n\n# Define function for creating the markdown formatted list of criteria met\ndef create_criteria_list(criteria_dict):\n    '''\n    Creates a string which contains a Markdown formatted list with icons to\n    indicate whether each criteria was met\n\n    Parameters:\n    -----------\n    criteria_dict : dict\n        Dictionary where keys are the criteria (variable name) and values are\n        Boolean (True/False of whether this study met the criteria)\n\n    Returns:\n    --------\n    formatted_list : string\n        Markdown formatted list\n    '''\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    # Create list with...\n    formatted_list = ''.join([\n        '* ' +\n        callout_icon[eval[key]] + # Icon based on whether it met criteria\n        ' ' +\n        value + # Full text description of criteria\n        '\\n' for key, value in criteria_dict.items()])\n    return(formatted_list)\n\n# Define groups of criteria\ncriteria_share_how = ['archive', 'id', 'license']\ncriteria_share_what = ['relevant', 'complete']\ncriteria_doc_struc = ['structure', 'documentation_sufficient', 'documentation_careful', 'documentation_readme']\ncriteria_run = ['execute', 'regenerated', 'hour']\n\n# Create text section\ndisplay(Markdown(f'''\nTo assess whether the author's materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\n\nThis study met **{sum(eval_list)} of the {len(eval_list)}** unique criteria items. These were as follows:\n\nCriteria related to how artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_how})}\n\nCriteria related to what artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_what})}\n\nCriteria related to the structure and documentation of the artefacts -\n\n{create_criteria_list({k: criteria[k] for k in criteria_doc_struc})}\n\nCriteria related to running and reproducing results -\n\n{create_criteria_list({k: criteria[k] for k in criteria_run})}\n'''))\n\n\nTo assess whether the author’s materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\nThis study met 3 of the 12 unique criteria items. These were as follows:\nCriteria related to how artefacts are shared -\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\nCriteria related to what artefacts are shared -\n\n✅ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\nCriteria related to the structure and documentation of the artefacts -\n\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n\nCriteria related to running and reproducing results -\n\n✅ Scripts can be successfully executed\n✅ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)"
  },
  {
    "objectID": "evaluation/badges.html#badges",
    "href": "evaluation/badges.html#badges",
    "title": "Journal badges",
    "section": "Badges",
    "text": "Badges\n\n\nCode\n# Full badge names\nbadge_names = {\n    # Open objects\n    'open_niso': 'NISO \"Open Research Objects (ORO)\"',\n    'open_niso_all': 'NISO \"Open Research Objects - All (ORO-A)\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos': 'COS \"Open Code\"',\n    'open_ieee': 'IEEE \"Code Available\"',\n    # Object review\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    'review_ieee': 'IEEE \"Code Reviewed\"',\n    # Results reproduced\n    'reproduce_niso': 'NISO \"Results Reproduced (ROR-R)\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    'reproduce_ieee': 'IEEE \"Code Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\n# Criteria required by each badge\nbadges = {\n    # Open objects\n    'open_niso': ['archive', 'id', 'license'],\n    'open_niso_all': ['archive', 'id', 'license', 'complete'],\n    'open_acm': ['archive', 'id'],\n    'open_cos': ['archive', 'id', 'license', 'complete', 'documentation_sufficient'],\n    'open_ieee': ['complete'],\n    # Object review\n    'review_acm_functional': ['documentation_sufficient', 'relevant', 'complete', 'execute'],\n    'review_acm_reusable': ['documentation_sufficient', 'documentation_careful', 'relevant', 'complete', 'execute', 'structure'],\n    'review_ieee': ['complete', 'execute'],\n    # Results reproduced\n    'reproduce_niso': ['regenerated'],\n    'reproduce_acm': ['regenerated'],\n    'reproduce_ieee': ['regenerated'],\n    'reproduce_psy': ['regenerated', 'hour', 'structure', 'documentation_readme'],\n}\n\n# Identify which badges would be awarded based on criteria\n# Get list of badges met (True/False) overall\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\naward_list = list(award.values())\n\n# Write introduction\n# Get list of badges met (True/False) by category\naward_open = [v for k,v in award.items() if k.startswith('open_')]\naward_review = [v for k,v in award.items() if k.startswith('review_')]\naward_reproduce = [v for k,v in award.items() if k.startswith('reproduce_')]\n\n# Create and display text for introduction\ndisplay(Markdown(f'''\nIn total, the original study met the criteria for **{sum(award_list)} of the {len(award_list)} badges**. This included:\n\n* **{sum(award_open)} of the {len(award_open)}** “open objects” badges\n* **{sum(award_review)} of the {len(award_review)}** “object review” badges\n* **{sum(award_reproduce)} of the {len(award_reproduce)}** “reproduced” badges\n'''))\n\n# Make function that creates collapsible callouts for each badge\ndef create_badge_callout(award_dict):\n    '''\n    Displays Markdown callouts created for each badge in the dictionary, showing\n    whether the criteria for that badge was met.\n\n    Parameters:\n    -----------\n    award_dict : dict\n        Dictionary where key is badge (as variable name), and value is Boolean\n        (whether badge is awarded)\n    '''\n    callout_appearance = {True: 'tip',\n                          False: 'warning'}\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    callout_text = {True: 'Meets all criteria:',\n                    False: 'Does not meet all criteria:'}\n\n    for key, value in award_dict.items():\n        # Create Markdown list with...\n        criteria_list = ''.join([\n            '* ' +\n            callout_icon[eval[k]] + # Icon based on whether it met criteria\n            ' ' +\n            criteria[k] + # Full text description of criteria\n            '\\n' for k in badges[key]])\n        # Create the callout and display it\n        display(Markdown(f'''\n::: {{.callout-{callout_appearance[value]} appearance=\"minimal\" collapse=true}}\n\n## {callout_icon[value]} {badge_names[key]}\n\n{callout_text[value]}\n\n{criteria_list}\n:::\n'''))\n\n# Create badge functions with introductions and callouts\ndisplay(Markdown('''\n### \"Open objects\" badges\n\nThese badges relate to research artefacts being made openly available.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('open_')})\n\ndisplay(Markdown('''\n### \"Object review\" badges\n\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('review_')})\n\ndisplay(Markdown('''\n### \"Reproduced\" badges\n\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('reproduce_')})\n\n\nIn total, the original study met the criteria for 3 of the 12 badges. This included:\n\n0 of the 5 “open objects” badges\n0 of the 3 “object review” badges\n3 of the 4 “reproduced” badges\n\n\n\n“Open objects” badges\nThese badges relate to research artefacts being made openly available.\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects (ORO)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\n\n\n\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects - All (ORO-A)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n\n\n\n\n\n\n\n\n\n\n\n\n❌ COS “Open Code”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n“Object review” badges\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Functional”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n✅ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n✅ Scripts can be successfully executed\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Reusable”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n✅ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n✅ Scripts can be successfully executed\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Reviewed”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n✅ Scripts can be successfully executed\n\n\n\n\n\n\n“Reproduced” badges\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n\n\n\n\n\n\n\n\n✅ NISO “Results Reproduced (ROR-R)”\n\n\n\n\n\nMeets all criteria:\n\n✅ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n✅ ACM “Results Reproduced”\n\n\n\n\n\nMeets all criteria:\n\n✅ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n✅ IEEE “Code Reproducible”\n\n\n\n\n\nMeets all criteria:\n\n✅ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ Psychological Science “Computational Reproducibility”\n\n\n\n\n\nDoes not meet all criteria:\n\n✅ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript"
  },
  {
    "objectID": "evaluation/badges.html#sources",
    "href": "evaluation/badges.html#sources",
    "title": "Journal badges",
    "section": "Sources",
    "text": "Sources\nNational Information Standards Organisation (NISO) (NISO Reproducibility Badging and Definitions Working Group (2021))\n\n“Open Research Objects (ORO)”\n“Open Research Objects - All (ORO-A)”\n“Results Reproduced (ROR-R)”\n\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\n\n“Artifacts Available”\n“Artifacts Evaluated - Functional”\n“Artifacts Evaluated - Resuable”\n“Results Reproduced”\n\nCenter for Open Science (COS) (Blohowiak et al. (2023))\n\n“Open Code”\n\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\n\n“Code Available”\n“Code Reviewed”\n“Code Reproducible”\n\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\n“Computational Reproducibility”"
  },
  {
    "objectID": "evaluation/reflections.html",
    "href": "evaluation/reflections.html",
    "title": "Reflections",
    "section": "",
    "text": "This page contains reflections on the facilitators and barriers to this reproduction, as well as a full list of the troubleshooting steps taken to reproduce this work."
  },
  {
    "objectID": "evaluation/reflections.html#what-facilitated-this-reproduction",
    "href": "evaluation/reflections.html#what-facilitated-this-reproduction",
    "title": "Reflections",
    "section": "What facilitated this reproduction?",
    "text": "What facilitated this reproduction?\n\nSimplicity of the model structure and code\nSimplicity of figures and similarity between figures\nSeveral of the model parameters are clearly provided in the article, tables and legends\nStructure of provided code (model largely in functions) made it easier when making changes to run it programmatically (although wasn’t all in functions)\nLots of comments in the code (including doc-string-style comments at the start of functions) that aided understanding of how it worked\nStated Python major version (although not minor version)"
  },
  {
    "objectID": "evaluation/reflections.html#what-would-have-helped-facilitate-this-reproduction",
    "href": "evaluation/reflections.html#what-would-have-helped-facilitate-this-reproduction",
    "title": "Reflections",
    "section": "What would have helped facilitate this reproduction?",
    "text": "What would have helped facilitate this reproduction?\nProvide tables as spreadsheets (e.g. .csv)\nProvide environment file with package versions\nModel run time\n\nState the expected run time\nLong run time made it difficult to run all the different scenarios, and so I add parallel processing to help speed this up\n\nInclude all model parameters and scenarios in the code\n\nSeveral parameters or scenarios were not incorporated in the code, and had to be added (e.g. with conditional logic to skip or change code run, removing hard-coding, adding parameters to existing)\n\nSet up model so that scenarios can be run programmatically\n\nSeveral parameters were hard coded\nModel was set to run a single scenario, and so needed to change to function that can call to easily vary parameters and run scenarios programmatically\n\nProvide code to produce figures"
  },
  {
    "objectID": "evaluation/reflections.html#full-list-of-troubleshooting-steps",
    "href": "evaluation/reflections.html#full-list-of-troubleshooting-steps",
    "title": "Reflections",
    "section": "Full list of troubleshooting steps",
    "text": "Full list of troubleshooting steps\n\n\n\n\n\n\nView list\n\n\n\n\n\nTroubleshooting steps are grouped by theme, and the day these occurred is given in brackets at the end of each bullet.\n\nTables\n\nTables in word document - had to copy into CSV, and then decided to reformat into long format for easier comparison and plotting (although I understand that the wide format provided are more readable/easy to look at) (2)\n\n\n\nEnvironment\n\nNo environment file, but does state it is Python 3, and mentions all packages used (numpy, pandas) (although not their versions).Selected versions on or prior to 29 August 2020 (2)\nEasily built environment with mamba and environment.yaml\n\n\n\nModel run time\n\nWhen initially running the model, I wasn’t certain how long to expect it to take. After 10 minutes, switched to using just one or two parameters, and when later ran with all (as provided in .py script), it took 19 minutes\nGiven there were then several different scenarios to run, this run time made it a bit trickier to work with and run the model. Hence, I add some parallel processing to help speed it up. This reduced run time to apx. 3 minutes. With the later addition of other parameters, the typical run time was 6 minutes (and we anticipate the original run time of 19 minutes would also have been much higher with these additional parameters added).\n\n\n\nIncluding all required parameters for base case and scenarios\n\nThe model script provided could not run with strength = 2, although this was a typical parameter in the model. I needed to add some code to deal with this situation (prevent from running certain combinations when strength is 2), as is described in the paper.\nThe model script provided only ran three shifts per day, but the paper presents results from 1, 2 or 3. I needed to add some code to conditionally alter the number of shifts, preventing certain sections of code from running to reduce the shift number.\nNo code was provided to run the scenarios. I changed the for loop into a function that can run scenarios programmatically\nSome parameters that we needed to change in scenarios were hard-coded and had to be changed into function inputs instead\nAs no code was provided for scenarios, I had to use the paper to understand how to implement them. They were generally pretty clear, although I found the random roster assignment scenario was a little trickier, as it required identifying that we needed to change two lines with stafflist.loc[temp,'rest']=1 to =0, which was immediately obvious.\nFor Figure 5, I had to guess the value for staff_per_shift\n\n\n\nCreating figures\n\nThe model script provided was only set up to provide results from days 7, 14 and 21. The figures require daily results, so I needed to modify the code to output that.\nNo code is provided to produce the figures, so I needed to write that from scratch.\n\n\n\nOther minor things to note\n\nThe code repeatedly outputs two warning messages - I set these to not appear - but presence of warning messages had no impact on functionality of code, beyond it being a verbose output\nThe results obtained looked very similar to the original article, with minimal differences that I felt to be within the expected variation from the model stochasticity. However, if seeds had been present, we would have been able to say with certainty. I did not feel I needed to add seeds during the reproduction to get the same results, but I will add seeds at a later point so that we can guarantee we are reproducing our own results on re-runs."
  },
  {
    "objectID": "logbook/logbook.html",
    "href": "logbook/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 6\n\n\n\n\n\n\ncompendium\n\n\n\n\n\n\n\n\n\nJul 26, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5\n\n\n\n\n\n\ncompendium\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4\n\n\n\n\n\n\nreproduce\n\n\nguidelines\n\n\n\n\n\n\n\n\n\nJul 24, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nsetup\n\n\nscope\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\nread\n\n\nscope\n\n\n\n\n\n\n\n\n\nJul 19, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html",
    "href": "logbook/posts/2024_07_26/index.html",
    "title": "Day 6",
    "section": "",
    "text": "Note\n\n\n\nFinishing up research compendium, and test-run from Tom."
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#untimed-troubleshooting-docker",
    "href": "logbook/posts/2024_07_26/index.html#untimed-troubleshooting-docker",
    "title": "Day 6",
    "section": "Untimed: Troubleshooting docker",
    "text": "Untimed: Troubleshooting docker\nTested local build of Docker image and running in the container but had an error:\n20.42 LibMambaUnsatisfiableError: Encountered problems while solving:\n20.42   - nothing provides numpy-base 1.23.3 py310h375b286_0 needed by numpy-1.23.3-py310hac523dd_0\n20.42 \n20.42 Could not solve for environment specs\n20.42 The following packages are incompatible\n20.42 ├─ matplotlib 3.5.1**  is installable with the potential options\n20.42 │  ├─ matplotlib 3.5.1 would require\n20.42 │  │  └─ python &gt;=3.10,&lt;3.11.0a0 , which can be installed;\n20.42 │  ├─ matplotlib 3.5.1 would require\n20.42 │  │  └─ python &gt;=3.7,&lt;3.8.0a0 , which can be installed;\n20.42 │  ├─ matplotlib 3.5.1 would require\n20.42 │  │  └─ matplotlib-base &gt;=3.5.1,&lt;3.5.2.0a0  with the potential options\n20.42 │  │     ├─ matplotlib-base 3.5.1 would require\n20.42 │  │     │  └─ python &gt;=3.10,&lt;3.11.0a0 , which can be installed;\n20.42 │  │     ├─ matplotlib-base 3.5.1 would require\n20.42 │  │     │  └─ python &gt;=3.7,&lt;3.8.0a0 , which can be installed;\n20.42 │  │     ├─ matplotlib-base 3.5.1 would require\n20.42 │  │     │  └─ numpy &gt;=1.19.2,&lt;2.0a0  with the potential options\n20.42 │  │     │     ├─ numpy [1.19.1|1.19.2] would require\n20.42 │  │     │     │  └─ python &gt;=3.6,&lt;3.7.0a0 , which can be installed;\n20.42 │  │     │     ├─ numpy [1.19.1|1.19.2|...|1.21.5] would require\n20.42 │  │     │     │  └─ python &gt;=3.7,&lt;3.8.0a0 , which can be installed;\n20.42 │  │     │     ├─ numpy [1.19.2|1.19.5|...|1.24.3], which can be installed;\n20.42 │  │     │     ├─ numpy [1.19.2|1.19.5|...|1.26.4] would require\n20.42 │  │     │     │  └─ python &gt;=3.9,&lt;3.10.0a0 , which can be installed;\n20.42 │  │     │     ├─ numpy [1.21.2|1.21.5|...|1.26.4] would require\n20.42 │  │     │     │  └─ python &gt;=3.10,&lt;3.11.0a0 , which can be installed;\n20.42 │  │     │     ├─ numpy [1.22.3|1.23.5|...|1.26.4] would require\n20.42 │  │     │     │  └─ python &gt;=3.11,&lt;3.12.0a0 , which can be installed;\n20.42 │  │     │     ├─ numpy 1.23.3 would require\n20.42 │  │     │     │  └─ numpy-base 1.23.3 py310h375b286_0, which does not exist (perhaps a missing channel);\n20.42 │  │     │     ├─ numpy 1.23.3 would require\n20.42 │  │     │     │  └─ numpy-base 1.23.3 py310h8e6c178_0, which does not exist (perhaps a missing channel);\n20.42 │  │     │     └─ numpy [1.26.0|1.26.2|1.26.3|1.26.4] would require\n20.42 │  │     │        └─ python &gt;=3.12,&lt;3.13.0a0 , which can be installed;\n20.42 │  │     └─ matplotlib-base 3.5.1 would require\n20.42 │  │        └─ python &gt;=3.9,&lt;3.10.0a0 , which can be installed;\n20.42 │  └─ matplotlib 3.5.1 would require\n20.42 │     └─ python &gt;=3.9,&lt;3.10.0a0 , which can be installed;\n20.42 ├─ numpy 1.19.1**  is installable with the potential options\n20.42 │  ├─ numpy [1.19.1|1.19.2], which can be installed (as previously explained);\n20.42 │  ├─ numpy [1.19.1|1.19.2|...|1.21.5], which can be installed (as previously explained);\n20.42 │  └─ numpy 1.19.1 conflicts with any installable versions previously reported;\n20.42 └─ python 3.8.5**  is not installable because it conflicts with any installable versions previously reported.\n20.42 \nI had a look at the conda/mamba environment created from the same environment on my machine and that had numpy-base 1.19.1. I tried adding this explicitly to the environment file and then running it again, although unresolved.\nI tried switching to start with a mamba image, following the documentation at https://micromamba-docker.readthedocs.io/en/latest/quick_start.html, but got the same error.\n# Use micromamba image\nFROM mambaorg/micromamba\n\n# Copy the environment file\nCOPY --chown=$MAMBA_USER:$MAMBA_USER ./reproduction/environment.yaml /tmp/environment.yaml\n\n# Create the environment\nRUN micromamba create -y -f /tmp/environment.yaml && \\\n    micromamba clean --all --yes\nI tried removing my local conda environment and rebuilt it with channel conda-forge and just requiring versions for the backdated packages (and not for those I add).\nname: lim2020\nchannels:\n  - conda-forge\ndependencies:\n  - numpy=1.19.1\n  - pandas=1.1.1\n  - python=3.8.5\n  - ipykernel\n  - matplotlib\n  - pytest\nThis built without issue, so I then add the dependencies it used:\nname: lim2020\nchannels:\n  - conda-forge\ndependencies:\n  - numpy=1.19.1\n  - pandas=1.1.1\n  - python=3.8.5\n  - ipykernel=6.29.5\n  - matplotlib=3.5.1\n  - pytest=8.3.2\nI then rebuilt the docker image, and that worked fine! For reference, this was the environment file from before:\nname: lim2020\nchannels:\n  - defaults\ndependencies:\n  - ipykernel\n  - matplotlib=3.5.1\n  - numpy=1.19.1\n  - pandas=1.1.1\n  - python=3.8.5\n  - pytest=7.4.4\nI then add lines back to the dockerfile so it can run jupyter lab, but had error /usr/local/bin/_entrypoint.sh: line 24: exec: mamba: not found.\n# Use micromamba image\nFROM mambaorg/micromamba\n\n# Copy the environment file\n# COPY --chown=$MAMBA_USER:$MAMBA_USER ./reproduction/environment.yaml /tmp/environment.yaml\n\n# Create and set the working directory to the container make copy simpler\nRUN mkdir /home/code\nWORKDIR /home/code\n\n# Copy all files across to container\nCOPY ./reproduction /home/code\n\n# Copy jupyter config file\nCOPY ./reproduction/docker/jupyter_notebook_config.py /root/.jupyter/jupyter_notebook_config.py\n\n# Create the environment\nRUN micromamba create -y -f /home/code/environment.yaml && \\\n    micromamba clean --all --yes\n\n# Make RUN commands use the new environment (not really necessary here)...\nSHELL [\"mamba\", \"run\", \"-n\", \"shoaib2022\", \"/bin/bash\", \"-c\"]\n\n# Declare port used by jupyter-lab\nEXPOSE 80\n\n# Launch JupyterLab\nCMD jupyter-lab /home/code/\nTried switching whole thing back to Dockerfile I had at the start.\nRealised I also needed to still add jupyterlab to environment.\nHowever, I now got a new error:\n[I 2024-07-26 12:35:36.291 ServerApp] jupyter_lsp | extension was successfully linked.\n[I 2024-07-26 12:35:36.297 ServerApp] jupyter_server_terminals | extension was successfully linked.\n[I 2024-07-26 12:35:36.304 ServerApp] jupyterlab | extension was successfully linked.\n[I 2024-07-26 12:35:36.306 ServerApp] Writing Jupyter server cookie secret to /root/.local/share/jupyter/runtime/jupyter_cookie_secret\n[I 2024-07-26 12:35:36.617 ServerApp] notebook_shim | extension was successfully linked.\n[I 2024-07-26 12:35:36.668 ServerApp] notebook_shim | extension was successfully loaded.\n[I 2024-07-26 12:35:36.671 ServerApp] jupyter_lsp | extension was successfully loaded.\n[I 2024-07-26 12:35:36.672 ServerApp] jupyter_server_terminals | extension was successfully loaded.\n[I 2024-07-26 12:35:36.674 LabApp] JupyterLab extension loaded from /opt/conda/envs/lim2020/lib/python3.8/site-packages/jupyterlab\n[I 2024-07-26 12:35:36.674 LabApp] JupyterLab application directory is /opt/conda/envs/lim2020/share/jupyter/lab\n[I 2024-07-26 12:35:36.674 LabApp] Extension Manager is 'pypi'.\n[I 2024-07-26 12:35:36.691 ServerApp] jupyterlab | extension was successfully loaded.\n[C 2024-07-26 12:35:36.692 ServerApp] Running as root is not recommended. Use --allow-root to bypass.\n\nERROR conda.cli.main_run:execute(125): `conda run /bin/bash -c jupyter-lab /home/code/` failed. (See above for error)\nThis was unexpected, as now the file matches exactly to the functional Dockerfile used for Shoaib et al. 2022, except for that it is environment.yaml and the environment name.\nI tried changing the environment channel back to defaults, rebuilt on local machine, recorded versions.\nname: lim2020\nchannels:\n  - defaults\n  - conda-forge\ndependencies:\n  - numpy=1.19.1\n  - pandas=1.1.1\n  - python=3.8.5\n  - ipykernel=6.28.0\n  - matplotlib=3.5.1\n  - pytest=7.4.4\n  - jupyterlab=4.0.11\nBuilt docker image. Still failed as before. It appears it’s not using the settings from the jupyter_notebook_config.py as that sets allow root as True, but the error is that running as root is not recommended that we can use –allow-root to bypass.\nTried switching to conda-forge again. No difference.\nBased on this post, I tried adding notebook to the environment and then re-running. And then it worked! Tested running the model: all fine."
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#untimed-docker-on-container-registry",
    "href": "logbook/posts/2024_07_26/index.html#untimed-docker-on-container-registry",
    "title": "Day 6",
    "section": "Untimed: Docker on container registry",
    "text": "Untimed: Docker on container registry\nActivated the GitHub action to publish the docker image on GHCR. Followed my instructions to build that and test run: all fine."
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#untimed-test-run-from-tom",
    "href": "logbook/posts/2024_07_26/index.html#untimed-test-run-from-tom",
    "title": "Day 6",
    "section": "Untimed: Test run from Tom",
    "text": "Untimed: Test run from Tom\nTom tested the scripts.\nThe docker container built correctly and launched.\nPytest ran fine and quick.\nreproduction.ipynb failed as it couldn’t access ../original_study/[CSV file], as docker container only contains reproduction/. Subsequently, I’ll add the required files to the container."
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html",
    "href": "logbook/posts/2024_07_23/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Note\n\n\n\nAdd parallel processing and reproduced supplementary tables 2-4 and Figure 2. Total time used: 10h 7m (25.3%)"
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#adding-parallel-processing",
    "href": "logbook/posts/2024_07_23/index.html#adding-parallel-processing",
    "title": "Day 3",
    "section": "09.40-11.12, 11.17-11.27: Adding parallel processing",
    "text": "09.40-11.12, 11.17-11.27: Adding parallel processing\nHaving now run the full model code that was provided, I can see that the loop produced a 10x4 table (for each of the end by day 7, 14 and 21). It varies:\n\nStaff strength (4, 6)\nFrequency of staff change (1, 3, 7, 14, 21)\nNumber of staff per shift (5, 10, 20, 30)\n\nIt doesn’t include:\n\nStaff strength 2 - should be easy to add to loop\nScenarios from paper (e.g. varying probability of secondary infection) - although that example is easy to change with p = 0.15 # secondary attack rate\n\nIt had quite a long run time (19m 8s) which will make it difficult to run all these variants. Hence, I will first try to introduce parallel processing to help speed up the reproduction.\n\nFirst, I modified model.py so the model is run by a function, that is then more easily callable from the reproduction notebook. Initially this was a single function, but then I realised I needed to divide it into a function that runs the model with a single set of parameters, and a function that loops through scenarios, to be easily compatable with parallel processing\nTo simplify/improve reusability of varying the number of staff per shift, I changed the results dataframe index from 0-4 to be based on the provided variants for staff per shift (e.g. 5, 10, 20, 30)\nWhilst running these, noted we do so fluctuation between re-runs (e.g. 0.47 to 0.54 for day 21 4-1)\nThen I introduced from multiprocessing import Pool and modified the nested for loop so that we can instead apply the function in parallel. I also had to modify how the results dataframes as created, as they were all modifying the same objects, which wouldn’t be possible in parallel.\n\nThis now ran in 2m 40s - 3m 6s. This is great, and will make running all the different scenarios much easier. By eye, the variation in results before and after parallel processing is very minimal, and all within the range I would expect due to there being no seed control.\nHid warnings and print progress message to enable cleaner output."
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#adding-parameters",
    "href": "logbook/posts/2024_07_23/index.html#adding-parameters",
    "title": "Day 3",
    "section": "11.31-11.36, 11.39-12.05: Adding parameters",
    "text": "11.31-11.36, 11.39-12.05: Adding parameters\nModified model.py so it has staff strength [2, 4, 6] but received error:\nFile \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 175, in run_model\n    fillroster1(staff_pool,f,Nday,stafflist,roster)\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 65, in fillroster1\n    temp = random.sample(stafflist[stafflist.loc[:,'rest']==0].index.values.tolist(),k=Nday)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/random.py\", line 363, in sample\n    raise ValueError(\"Sample larger than population or is negative\")\nValueError: Sample larger than population or is negative\nI think this is related to strength 2, which is set to NA in the paper when there are two or three shifts per day, stating that it is “not available as the number of staff per shift was too low to simulate under the required conditions”. Lim et al. (2020)\nI wasn’t certain how to alter the shifts per day from the model, but I tried commenting out shift 2 and 3 in contact(). to see if the model would run. However, I still got the error from above. I introduced error handling, to set the result to NaN if there was a Value Error. With those sections still commented, and only running strength 2, the only results it output were for 2-21.\nI tried uncommenting shifts 2 and 3 and running for strength 2. However, this again only output results for 2-21."
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#troubleshooting-staff-strength-2",
    "href": "logbook/posts/2024_07_23/index.html#troubleshooting-staff-strength-2",
    "title": "Day 3",
    "section": "12.40-13.18, 13.20-13.44: Troubleshooting staff strength 2",
    "text": "12.40-13.18, 13.20-13.44: Troubleshooting staff strength 2\nWe don’t expect it to work when there are three shifts per day, so I tried again to figure out how to successfully change it to one shift per day…\n\nCommented out shift 2 and 3 sections from contact() abd creation of shift 2 and 3 rosters in restartsim(). Got error:\n\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 169, in run_model\n    fillroster1(staff_pool,f,Nday,stafflist,roster)\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 63, in fillroster1\n    roster.iloc[f*i+j] = temp\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/indexing.py\", line 670, in __setitem__\n    iloc._setitem_with_indexer(indexer, value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1802, in _setitem_with_indexer\n    self.obj._mgr = self.obj._mgr.setitem(indexer=indexer, value=value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 534, in setitem\n    return self.apply(\"setitem\", indexer=indexer, value=value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 406, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 885, in setitem\n    values[indexer] = value\nValueError: cannot copy sequence with size 18 to array axis with dimension 10\n\"\"\"\n\nThis might actually be the issue we were looking for - that we can’t fill up the roster with that staff number. I tried running with strength 4, which should work regardless, but get a similar error\n\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 169, in run_model\n    fillroster1(staff_pool,f,Nday,stafflist,roster)\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 63, in fillroster1\n    roster.iloc[f*i+j] = temp\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/indexing.py\", line 670, in __setitem__\n    iloc._setitem_with_indexer(indexer, value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1802, in _setitem_with_indexer\n    self.obj._mgr = self.obj._mgr.setitem(indexer=indexer, value=value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 534, in setitem\n    return self.apply(\"setitem\", indexer=indexer, value=value)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 406, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 885, in setitem\n    values[indexer] = value\nValueError: cannot copy sequence with size 9 to array axis with dimension 5\n\nTo be sure it’s not an error I’ve introduced, I went back to the original model code and made a fresh notebook, commenting out the same sections, but with the same result\nI worked through the code, trying to spot anything I should’ve also changed, and noticed that:\n\nNday = staffpershift1 + staffpershift2 + staffpershift3\nThen used in fillroster1(staff_pool,f,Nday)\nAs temp = random.sample(stafflist[stafflist.loc[:,'rest']==0].index.values.tolist(),k=Nday)\n\nI changed that to Nday = staffpershift1, and this then worked!\n\nI then add a parameter to run_scenarios() to control number of shifts per day, and made those commented out sections into conditional logic depending on whether it’s 1, 2 or 3 days.\nI had to change the results dataframe (as it was set up to only save results for one variant of shifts per day). I decided the simplest solution - that would also make creating the figures later easier - would be to save it in long format.\nI also set the results to NaN if it found that the input parameters were staff strength 2 and more than one shift per day.\nI then ran the whole model, with all the parameter variants."
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#supplementary-table-2",
    "href": "logbook/posts/2024_07_23/index.html#supplementary-table-2",
    "title": "Day 3",
    "section": "13.55-14.09: Supplementary table 2",
    "text": "13.55-14.09: Supplementary table 2\nCompared the results for supplementary table 2, and found nearly all were identical.\nThe maximum absolute difference observed was 0.07, which is within the normal variation I observed above between runs of the model without seed control.\nHence, consider this successfully reproduced at 14.09.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 277\n\n# Times from today\ntimes = [\n    ('09.40', '11.12'),\n    ('11.17', '11.27'),\n    ('11.31', '11.36'),\n    ('11.39', '12.05'),\n    ('12.40', '13.18'),\n    ('13.20', '13.44'),\n    ('13.55', '14.09')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 209m, or 3h 29m\nTotal used to date: 486m, or 8h 6m\nTime remaining: 1914m, or 31h 54m\nUsed 20.2% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#supplementary-table-3-and-4",
    "href": "logbook/posts/2024_07_23/index.html#supplementary-table-3-and-4",
    "title": "Day 3",
    "section": "14.10-14.14, 14.25-14.28, 14.33-14.44, 14.49-14.58: Supplementary table 3 and 4",
    "text": "14.10-14.14, 14.25-14.28, 14.33-14.44, 14.49-14.58: Supplementary table 3 and 4\nRe-ran and renamed base scenario with 15% probability of secondary infection, and then ran model again but with 5% and 30% probability. This took about 21 minutes.\nWhile that ran, I worked on speeding up the model code further, by changing the n(0,100) for loop into a map statement.\nMax difference for each was 0.1, which I feel is within normal variation observed. This was reaffirmed by looking at the few examples where the results were different by more than 0.05, which were few and not felt to be noteable.\nFurther confirmed by the fact that, upon re-run, the max difference for supplementary table 2 was now 0.12, when before it was 0.07.\nIn all cases, the overwhelming majority of points are very similar, and these could be considered normal variation within the stochasticity of the model.\nWould considered each complete at 14.58.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 277\n\n# Times from today\ntimes = [\n    ('09.40', '11.12'),\n    ('11.17', '11.27'),\n    ('11.31', '11.36'),\n    ('11.39', '12.05'),\n    ('12.40', '13.18'),\n    ('13.20', '13.44'),\n    ('13.55', '14.09'),\n    ('14.10', '14.14'),\n    ('14.25', '14.28'),\n    ('14.33', '14.44'),\n    ('14.49', '14.58')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 236m, or 3h 56m\nTotal used to date: 513m, or 8h 33m\nTime remaining: 1887m, or 31h 27m\nUsed 21.4% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#improving-model-run-time",
    "href": "logbook/posts/2024_07_23/index.html#improving-model-run-time",
    "title": "Day 3",
    "section": "15.08-15.19: Improving model run time",
    "text": "15.08-15.19: Improving model run time\nAttempted to improve run time further, although then decided not to pursue this, as I have already add parallel processing, and as had hit an error and didn’t want to spend too much time on it as not essential to reproduciton.\n  File \"/home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction/scripts/model.py\", line 275, in run_model\n    res_median = np.median(results, axis=0)\n  File \"&lt;__array_function__ internals&gt;\", line 5, in median\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/numpy/lib/function_base.py\", line 3520, in median\n    r, k = _ureduce(a, func=_median, axis=axis, out=out,\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/numpy/lib/function_base.py\", line 3429, in _ureduce\n    r = func(a, **kwargs)\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/numpy/lib/function_base.py\", line 3555, in _median\n    part = partition(a, kth, axis=axis)\n  File \"&lt;__array_function__ internals&gt;\", line 5, in partition\n  File \"/home/amy/mambaforge/envs/lim2020/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 748, in partition\n    a.partition(kth, axis=axis, kind=kind, order=order)\nTypeError: '&lt;' not supported between instances of 'NoneType' and 'NoneType'\n\"\"\""
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#figure-2",
    "href": "logbook/posts/2024_07_23/index.html#figure-2",
    "title": "Day 3",
    "section": "15.25-15.42, 15.49-16.55: Figure 2",
    "text": "15.25-15.42, 15.49-16.55: Figure 2\nThe total staff is 6, 120, or 4 * 30 staff per shift. The total number of staff is expressed as multiples of staff in the first shift, and referred to as staff strength, and discussed in section 2.1.2.\nI realised that my current runs of the model had just been outputting the results for day 7, 14 and 21, but I would need to keep all the results to produce these figures. I modified the model.py to allow this, and then re-ran the base 15 model.\nThe model varies shifts_per_day, staff_per_shift and strength.\nI was initially unsure on the frequency of staff changes. The shift arrangement is discussed in 2.1.3: “The staff was assumed to change shift after a single day (shift), as well as after working 3, 7, 14, 21 consecutive days. After each shift, the simulated staff is assumed to return and stay at home for at least the same number of days as the shift before being randomly assigned to a new shift with the other off-duty colleagues.” Lim et al. (2020) The figure 2 legend mentions that the simulated staff work non-consecutive days. From these sections, I think I am correct in assuming that the default is for it to be freq=1, and so I have set that.\nAdd matplotlib to environment but didn’t specify to older version, as appears the figures in the article are produced in excel.\nWrote code to extract the required results from the dataframe and produce the figure.\nLooks just like paper. Happy that this is reproduced at 16.55."
  },
  {
    "objectID": "logbook/posts/2024_07_23/index.html#timings",
    "href": "logbook/posts/2024_07_23/index.html#timings",
    "title": "Day 3",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 277\n\n# Times from today\ntimes = [\n    ('09.40', '11.12'),\n    ('11.17', '11.27'),\n    ('11.31', '11.36'),\n    ('11.39', '12.05'),\n    ('12.40', '13.18'),\n    ('13.20', '13.44'),\n    ('13.55', '14.09'),\n    ('14.10', '14.14'),\n    ('14.25', '14.28'),\n    ('14.33', '14.44'),\n    ('14.49', '14.58'),\n    ('15.08', '15.19'),\n    ('15.25', '15.42'),\n    ('15.49', '16.55')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 330m, or 5h 30m\nTotal used to date: 607m, or 10h 7m\nTime remaining: 1793m, or 29h 53m\nUsed 25.3% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_25/index.html",
    "href": "logbook/posts/2024_07_25/index.html",
    "title": "Day 5",
    "section": "",
    "text": "Note\n\n\n\nReflections, summary report and research compendium."
  },
  {
    "objectID": "logbook/posts/2024_07_25/index.html#untimed-reflections",
    "href": "logbook/posts/2024_07_25/index.html#untimed-reflections",
    "title": "Day 5",
    "section": "Untimed: Reflections",
    "text": "Untimed: Reflections\nCompleted reflections page."
  },
  {
    "objectID": "logbook/posts/2024_07_25/index.html#untimed-summary-report",
    "href": "logbook/posts/2024_07_25/index.html#untimed-summary-report",
    "title": "Day 5",
    "section": "Untimed: Summary report",
    "text": "Untimed: Summary report\nCompleted summary report."
  },
  {
    "objectID": "logbook/posts/2024_07_25/index.html#untimed-consensussecond-opinion",
    "href": "logbook/posts/2024_07_25/index.html#untimed-consensussecond-opinion",
    "title": "Day 5",
    "section": "Untimed: Consensus/second opinion",
    "text": "Untimed: Consensus/second opinion\nTom agreed that all items had been successfully reproduced.\nRegarding the uncertainties from the evaluation:\n\nBadges - “Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)” - I have tentatively marked this as unmet. I feel that the script provided was well-structured (with functions and lots of comments throughout the script, including comments playing the role of docstrings at the start of the functions). However, I have set it as unmet as I still had to make several changes in order to easily use it and change parameters for scenarios (as parameters were often hard-coded in the for loop, or in the functions themselves)\n\nYes I agree this is unmet. Ideally there is an simple way to experiment with the model. In an ideal world the authors provide a reproducible Analytical Pipeline (RAP) for simulation where each experiment can reproduced without lots of manual setup.\n\nSTRESS-DES - “2.5.3 Components - resources” and “2.5.4 Components - queues” - as described on the page, I have marked this as non-applicable, but wanted to double-check if that sounded right to you\n\nI agree. There aren’t any to document.\n\nChecklist derived from ISPOR-SDM - “6 Is the target population described?” - I was very uncertain on whether this would be not applicable, fully met, or unmet! Uncertainty as this is not a typical scenario where you’re e.g. focusing on a disease/treatment, and have a population of patients. So I wasn’t really sure what population description would be required to meet this. It does describe the results from a survey on attributes of lab people to PPE.\n\nYes ISPOR is typically targeted at patients. But my view was that the population modelled was the lab staff. If you think they are adequately described in the paper I would mark this as met. Happy to discuss."
  },
  {
    "objectID": "logbook/posts/2024_07_25/index.html#untimed-research-compendium",
    "href": "logbook/posts/2024_07_25/index.html#untimed-research-compendium",
    "title": "Day 5",
    "section": "Untimed: Research compendium",
    "text": "Untimed: Research compendium\n\nAdd seed to model.py so can reproduce own results\n\nstart_seed in run_scenarios() (default 0) and run_model(), used as first line in the replciation for loop, np.random.seed(start_seed + n)\nRan model with limited number of parameters twice to confirm I got the same results each time, but they came out with some differences\nI tried also adding random.seed(start_seed + n) (as the code samples using random and numpy), and then produced matching results\n\n\nres1 = model.run_scenarios(strength=[4], staff_change=[7], shift_day=[1])\nres2 = model.run_scenarios(strength=[4], staff_change=[7], shift_day=[1])\nres1.compare(res2)\n\nRe-ran all scenarios from scratch (with seed control now in place), and saved run times\nAdd tests\n\nAdd pytest to environment (originally also pytest-xdist and pip to environment, but then decided against this as there was already parallel processing add to the code itself)\nWrote test for two scenarios (using similar structure as did from first reproduction) - but not for all scenarios, purely due to long run time.\nRequires __init__.py in tests/ and in model scripts/\n\nAdd Dockerfile\nUpdate reproduction README"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Lim et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nLim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Lim et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nLim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Lim et al. 2020",
    "section": "Project team",
    "text": "Project team\n\nConducting this reproduction:\n\nAmy Heather \n\nProviding support during the reproduction:\n\nThomas Monks \nAlison Harper \n\nOther members of the team on STARS:\n\nNavonil Mustafee \nAndrew Mayne"
  },
  {
    "objectID": "index.html#protocol",
    "href": "index.html#protocol",
    "title": "Reproducing Lim et al. 2020",
    "section": "Protocol",
    "text": "Protocol\nThe protocol for this work is summarised in the diagram below and archived on Zenodo:\n\nHeather, A., Monks, T., Harper, A., Mustafee, N., & Mayne, A. (2024). Protocol for assessing the computational reproducibility of discrete-event simulation models on STARS. Zenodo. https://doi.org/10.5281/zenodo.12179846.\n\n\n\n\nWorkflow for computational reproducibility assessment"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Lim et al. 2020",
    "section": "Citation",
    "text": "Citation\nAPA:\nHeather A., Monks T., Harper A. (2024). STARS: Computational reproducibility of Lim et al. 2020 (version 0.1.0). URL: https://github.com/pythonhealthdatascience/stars-reproduce-lim-2020\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Lim et al. 2020",
    "section": "License",
    "text": "License\nSee License page."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html",
    "href": "logbook/posts/2024_07_24/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Note\n\n\n\nFinished reproduction and completed evaluation against guidelines. Total time used for reproduction: 12h 27m (31.1%). Time used for evaluation: 1h 30m."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#figure-3",
    "href": "logbook/posts/2024_07_24/index.html#figure-3",
    "title": "Day 4",
    "section": "09.03-09.27, 09.30-09.46: Figure 3",
    "text": "09.03-09.27, 09.30-09.46: Figure 3\nThis used data I had already produced, and I could easily reuse my function from Figure 2 - just had to input the right parameters. Add letters to subplot to improve clarity.\nFeel to be successfully reproduced at 09.46\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 40m, or 0h 40m\nTotal used to date: 647m, or 10h 47m\nTime remaining: 1753m, or 29h 13m\nUsed 27.0% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#figure-4",
    "href": "logbook/posts/2024_07_24/index.html#figure-4",
    "title": "Day 4",
    "section": "10.00-10.08: Figure 4",
    "text": "10.00-10.08: Figure 4\nAgain, could easily use prior data and functions, just filling in with all the right parameters.\nHappy that this is successfully reproduced at 10.08.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46'),\n    ('10.00', '10.08')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 48m, or 0h 48m\nTotal used to date: 655m, or 10h 55m\nTime remaining: 1745m, or 29h 5m\nUsed 27.3% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#supplemental-table-6",
    "href": "logbook/posts/2024_07_24/index.html#supplemental-table-6",
    "title": "Day 4",
    "section": "10.19-10.31, 10.44-10.54, 11.19-11.25, 11.35-11.42: Supplemental table 6",
    "text": "10.19-10.31, 10.44-10.54, 11.19-11.25, 11.35-11.42: Supplemental table 6\nThe protective measures have odds ratios provided in supplemental table 1. As described in section 2.4, these reflect the reduced probability of infection, and “the odds ratios [are] adopted for the reduction of p in the simulation”. Lim et al. (2020)\np is the secondary attack rate / probability of transmission between infected and susceptible staff. It is set at 15% (base), with scenarios of 5% and 30%.\nThe supplementary table lists odds ratios of:\n\nWearing gloves: 0.45\nWearing surgical mask: 0.32\nWearing gown: 0.23\nWearing N95 mask: 0.09\n\nIn supplemental table 6, it states that it is:\n\n“Proportion of simulated laboratory staff infected by COVID-19 in base scenario with 15% probability of secondary infection at the end of day 14 of the simulation with the staff observing workplace social distancing (by reducing the contact rate by half) and using various personal protective equipment. In this scenario, the simulated staff worked fixed alternating workdays (i.e. fixed consecutive days on, and fixed minimum consecutive days off). The results shown are the median of 100 cycles of simulation. NA = not available as the number of staff per shift is too low to simulate under the required conditions.” Lim et al. (2020)\n\nHence, it appears we adjust p=0.15 by the odds ratios, to reduce the odds of transmission. It wasn’t immediately clear to me how to perform this calculation, although I quickly realised that it was likely to be multiplication, which results in the lowest odds for N95 (as we expect, with article results mentioning that “the strongest protective effect is seen with the N95 masks”).\n\nprint(f'''\nGloves: {0.15*0.45}\nSurgical mask: {0.15*0.32}\nGown: {0.15*0.32}\nWearing N95 mask: {0.15*0.09}\n''')\n\n\nGloves: 0.0675\nSurgical mask: 0.048\nGown: 0.048\nWearing N95 mask: 0.0135\n\n\n\nAs p/secondary_attack_rate is already a parameter in run_scenarios(), I could easily set up and run these scenarios.\nThis scenario is used in Figure 5 and Supplemental Table 6. Supplemental table 6 includes an additional scenario of workplace social distancing, which it states is achieved by reducing the contact rate (c) by half. In model.py (and as stated in section 2.5) this is used as follows:\nc1 = 0.40*staffpershift1  # number of contact for shift 1\nc2 = 0.40*staffpershift2  # number of contact for shift 2\nc3 = 0.40*staffpershift3  # number of contact for shift 3\nHence, we can simply half 0.4 to use 0.2 instead. I set this up as a parameter that can be altered within run_scenarios() inputs. These was one section that also used 0.4, and I wasn’t sure whether I needed to change that also:\nstaffpershift2 = int(staffpershift1*0.4)\nstaffpershift3 = int(staffpershift1*0.4)\nAs it is not calculating the contact rate, I have assumed not for now.\nRan all these and compared against the supplementary table. Very similar, with minimal variation as would expect from stochasticity of model, and so I am happy to mark this as reproduced at 11.42.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46'),\n    ('10.00', '10.08'),\n    ('10.19', '10.31'),\n    ('10.44', '10.54'),\n    ('11.19', '11.25'),\n    ('11.35', '11.42')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 83m, or 1h 23m\nTotal used to date: 690m, or 11h 30m\nTime remaining: 1710m, or 28h 30m\nUsed 28.7% of 40 hours max\n\n\n\n\n\n\n\n\nReflections\n\n\n\nSo far, reproduction has been facilitated by:\n\nModel simplicity\nSimplicity of figures and similarity between figures\nSome clear model parameters from article, tables and legends\nSome parameters that we need to alter were already set up as function inputs that can be changed programmatically\nLots of comments in the code to aid understanding\n\nBarriers:\n\nSome slightly unclear scenarios (or that take a little longer to figure out)\nNo code for scenarios or figures or tables\nSome parameters that we need to alter are hard coded\nRun time"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#supplementary-table-5",
    "href": "logbook/posts/2024_07_24/index.html#supplementary-table-5",
    "title": "Day 4",
    "section": "11.48-12.06, 12.09-12.15: Supplementary table 5",
    "text": "11.48-12.06, 12.09-12.15: Supplementary table 5\nSupplementary table 5 has random roster assignment (which is used alongside table 6 to create figure 5).\nThis is only run with one shift per day.\nIt was initially unclear to be how to implement this scenario. I looked at the available description:\n\nThe random roster assignment is described in 2.1.3 as “Additionally, the scenario where the simulated staff are randomly assigned a new shift without fixed rest days are also examined in laboratories with a single shift.” This is as opposed to the alternating shift roster where “the staff was assumed to change shift after a single day (shift), as well as after working 3, 7, 14, 21 consecutive days. After each shift, the simulated staff is assumed to return and stay at home for at least the same number of days as the shift before being randomly assigned to a new shift with the other off-duty colleagues. For example, if a simulated staff works for 3 consecutive days, the staff will be off duty for at least the 3 following days.” Lim et al. (2020)\nIn the supplementary materials, the random roster assignment is described as working “without predefined minimum rest day (i.e. random shift assignment after each shift)” Lim et al. (2020)\n\nLooking at model.py…\n\nI can see that Lim et al. 2020 have commented above fillroster1() that this function is to full up the roster with staff, and that it ensures that the staff rest for a minimal period after working.\nIn the roster dataframe, the comments state that 0 = not resting and 1 = resting for the rest column.\nThe rest column is populated by fillroster1(). It samples from the staff in stafflist that are marked as not resting, sample the number of staff needed for that day. This is done as many times as needed for simulation (e.g. if shift changes every day (f=1), then the number of times will repeat is 21 (num_cycle=int(21/f))). When it does this, it marks a rest day with the line stafflist.loc[temp,'rest']=1. I’m assuming that conditionally removing that line may be how we implement the scenario\n\nI add this to model.py.\nAs for other tables, results were very similar, and I was satisfied this was reproduced at 12.15.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46'),\n    ('10.00', '10.08'),\n    ('10.19', '10.31'),\n    ('10.44', '10.54'),\n    ('11.19', '11.25'),\n    ('11.35', '11.42'),\n    ('11.48', '12.06'),\n    ('12.09', '12.15')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 107m, or 1h 47m\nTotal used to date: 714m, or 11h 54m\nTime remaining: 1686m, or 28h 6m\nUsed 29.8% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#removed-mistake-in-scope",
    "href": "logbook/posts/2024_07_24/index.html#removed-mistake-in-scope",
    "title": "Day 4",
    "section": "12.16-12.20: Removed mistake in scope",
    "text": "12.16-12.20: Removed mistake in scope\nIn heinsight, I realised we had made a mistake with the scope, as we had set in-text result 1 as:\n\n“The strongest protective effect is seen with the N95 masks (nearly equivalent to a FFP2 mask), which has the effect of reducing the odds of transmission by 0.09” Lim et al. (2020)\n\nHowever, I realised that this is not a result of the model, but instead just stating the odds ratio used to alter the probability of secondary transmission, as presented in supplementary table 1.\n\nAs such, I removed this from the scope."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#figure-5",
    "href": "logbook/posts/2024_07_24/index.html#figure-5",
    "title": "Day 4",
    "section": "12.21-12.50: Figure 5",
    "text": "12.21-12.50: Figure 5\nFor Figure 5, I could use the data and functions already produced.\nIt wasn’t immediately clear what some of the parameters (strength and staff_per_shift).\nI had this for staff_change since the first figure, and in that case used 1 based on this appearing to be the default value from the description. However, it was not possible to take the same approach for these, as none was marked as more clearly a default.\nI then noticed that section 3.2 mentions that it is “a single shift per day, an overall staff pool of twice the number of staff per shift and has fixed alternating workday”. Lim et al. (2020). Hence, it seems it uses strength=2.\nI decided to try staff_per_shift=20 based on the prior Figure 4, as that had used that as its default value across the subplots. However, I felt it looked a little different, so I tried with 10, 20 and 30 respectively (as below).\n  \nOriginal, for reference, from Lim et al. (2020):\n\n\n\nFigure 5\n\n\nI felt that the results were more similar when plot with 30 staff per shift. Given that I hadn’t found any note anywhere of what parameter was used for this figure, I decided to switch to that.\nAt this point, I am satisifed that the variation between the original and reproduction is within the expected variation from the stochasticity of the model, and so consider reproduced at 12.50.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46'),\n    ('10.00', '10.08'),\n    ('10.19', '10.31'),\n    ('10.44', '10.54'),\n    ('11.19', '11.25'),\n    ('11.35', '11.42'),\n    ('11.48', '12.06'),\n    ('12.09', '12.15'),\n    ('12.16', '12.20'),\n    ('12.21', '12.50')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 140m, or 2h 20m\nTotal used to date: 747m, or 12h 27m\nTime remaining: 1653m, or 27h 33m\nUsed 31.1% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#untimed-displaying-the-tables-on-reproduction-success-page",
    "href": "logbook/posts/2024_07_24/index.html#untimed-displaying-the-tables-on-reproduction-success-page",
    "title": "Day 4",
    "section": "Untimed: Displaying the tables on reproduction success page",
    "text": "Untimed: Displaying the tables on reproduction success page\nDue to size of tables, created function to preview and show differences in the tables, rather than just sharing the whole tables, as I normally would."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#timings-for-reproduction",
    "href": "logbook/posts/2024_07_24/index.html#timings-for-reproduction",
    "title": "Day 4",
    "section": "Timings for reproduction",
    "text": "Timings for reproduction\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 607\n\n# Times from today\ntimes = [\n    ('09.03', '09.27'),\n    ('09.30', '09.46'),\n    ('10.00', '10.08'),\n    ('10.19', '10.31'),\n    ('10.44', '10.54'),\n    ('11.19', '11.25'),\n    ('11.35', '11.42'),\n    ('11.48', '12.06'),\n    ('12.09', '12.15'),\n    ('12.16', '12.20'),\n    ('12.21', '12.50')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 140m, or 2h 20m\nTotal used to date: 747m, or 12h 27m\nTime remaining: 1653m, or 27h 33m\nUsed 31.1% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#stars-framework",
    "href": "logbook/posts/2024_07_24/index.html#stars-framework",
    "title": "Day 4",
    "section": "13.57-14.03: STARS framework",
    "text": "13.57-14.03: STARS framework"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#journal-badges",
    "href": "logbook/posts/2024_07_24/index.html#journal-badges",
    "title": "Day 4",
    "section": "14.07-14.16: Journal badges",
    "text": "14.07-14.16: Journal badges\ncomplete: marked as no as I had to write code for scenarios, figures and tables\nstructure: uncertain, tentatively marked as unmet, as I feel what was provided was well structured (with comments akin to docstrings at the start of functions, lots of comments throughout the script), although I am uncertain as I also had to make several changes in order to more easily use it (as some of the parameters were hard-coded in the for loop or functions, etc.)\ndocumentation_sufficient: it meets that documentation is sufficient to “understand how it works, to enable it to be run”, but not “including package versions”, and so marked as unmet"
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#stress-des",
    "href": "logbook/posts/2024_07_24/index.html#stress-des",
    "title": "Day 4",
    "section": "14.17-15.05: STRESS-DES",
    "text": "14.17-15.05: STRESS-DES\n2.5.3 Components - resources and 2.5.4 Components - queues - uncertain, want to double check whether I am correct in marking as N/A."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#checklist-derived-from-ispor-sdm",
    "href": "logbook/posts/2024_07_24/index.html#checklist-derived-from-ispor-sdm",
    "title": "Day 4",
    "section": "16.06-16.26: Checklist derived from ISPOR-SDM",
    "text": "16.06-16.26: Checklist derived from ISPOR-SDM\n6 Is the target population described? - uncertain, set as N/A, but could you argue fully met, given the context and what would be relevant to describe about the target population? Or is this wanting numbers of laboratories and so on? Partially? Not met? Very unsure!\n12 Is cross validation performed and reported - In previous studies, if they have mentioned that it was not possible to compare due to there not being other relevant studies, I’ve set as N/A. However, they do not mention this. Also, they state that estimates on protective effectives of PPE for severe acute respiratory syndrome (SARS) “should be broadly applicable to the current COVID-19 situation”, so it’s assumed that there could be models in that context, and as not described as being a lack of models in this paper, could reasonably assume that there could be relevant models available that were not identified and used for cross validation."
  },
  {
    "objectID": "logbook/posts/2024_07_24/index.html#wrote-email-to-tom-and-alison-sharing-uncertainities-from-evaluation",
    "href": "logbook/posts/2024_07_24/index.html#wrote-email-to-tom-and-alison-sharing-uncertainities-from-evaluation",
    "title": "Day 4",
    "section": "16.40-16.47: Wrote email to Tom and Alison sharing uncertainities from evaluation",
    "text": "16.40-16.47: Wrote email to Tom and Alison sharing uncertainities from evaluation\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('13.57', '14.03'),\n    ('14.07', '14.16'),\n    ('14.17', '15.05'),\n    ('16.06', '16.26'),\n    ('16.40', '16.47')]\n\ncalculate_times(used_to_date, times, limit=False)\n\nTime spent today: 90m, or 1h 30m\nTotal used to date: 90m, or 1h 30m"
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html",
    "href": "logbook/posts/2024_07_19/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Note\n\n\n\nSet-up, read article and define scope. Total time used: 1h 22m (3.4%)"
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#create-repository",
    "href": "logbook/posts/2024_07_19/index.html#create-repository",
    "title": "Day 1",
    "section": "14.05-14.34: Create repository",
    "text": "14.05-14.34: Create repository\n\nSet up repository using template\nModified files to refer to Lim et al. 2020\nBuilt Python environment to create the book.\nPreviously sent a detailed email to the authors on Thursday 11th and Friday 12th July to inform about the study and ask if they would be happy to add an open license. Looking over that email, I don’t think it is necessary to email again, but will double-check with someone else on STARS."
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#upload-code-to-the-repository",
    "href": "logbook/posts/2024_07_19/index.html#upload-code-to-the-repository",
    "title": "Day 1",
    "section": "14.36-14.38: Upload code to the repository",
    "text": "14.36-14.38: Upload code to the repository\nThe study code is available at https://github.com/chaose5/COVID-roster-simulation and shared with an open MIT license, which was kindly added following our email. As it is MIT, we do not need to update our license."
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#upload-journal-article-to-the-repository",
    "href": "logbook/posts/2024_07_19/index.html#upload-journal-article-to-the-repository",
    "title": "Day 1",
    "section": "14.39-15.00: Upload journal article to the repository",
    "text": "14.39-15.00: Upload journal article to the repository\nThe journal article is free to view online as it is included with PubMed Central (PMC) - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7486214/. The copyright statement provided is:\n\n“Copyright © 2020 The Canadian Society of Clinical Chemists. Published by Elsevier Inc. All rights reserved. Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company’s public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.”\n\nSince the COVID-19 resource centre remains active, I understand that this means we are free to upload this article and its supplementary materials to this repository, and to use images from this article with attribution.\nI uploaded the article, figures and supplementary materials, and then completed study_publication.qmd, converting the docx files to pdf for easy display via e.g. libreoffice --headless --convert-to pdf original_study/supp1.docx."
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#read-journal-article",
    "href": "logbook/posts/2024_07_19/index.html#read-journal-article",
    "title": "Day 1",
    "section": "15.16-15.34: Read journal article",
    "text": "15.16-15.34: Read journal article"
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#plan-scope-of-reproduction",
    "href": "logbook/posts/2024_07_19/index.html#plan-scope-of-reproduction",
    "title": "Day 1",
    "section": "15.35-15.47: Plan scope of reproduction",
    "text": "15.35-15.47: Plan scope of reproduction\nFollowing the read through, I filled out scope.qmd with my thoughts on scope of the reproduction."
  },
  {
    "objectID": "logbook/posts/2024_07_19/index.html#timings",
    "href": "logbook/posts/2024_07_19/index.html#timings",
    "title": "Day 1",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('14.05', '14.34'),\n    ('14.36', '14.38'),\n    ('14.39', '15.00'),\n    ('15.16', '15.34'),\n    ('15.35', '15.47')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 82m, or 1h 22m\nTotal used to date: 82m, or 1h 22m\nTime remaining: 2318m, or 38h 38m\nUsed 3.4% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html",
    "href": "logbook/posts/2024_07_22/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Note\n\n\n\nReformat tables, consensus on scope, setup environment, first run of model. Total time used: 4h 37m (11.5%)"
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#converting-supplementary-tables-to-csv",
    "href": "logbook/posts/2024_07_22/index.html#converting-supplementary-tables-to-csv",
    "title": "Day 2",
    "section": "09.18-10.08, 10.18-11.38: Converting supplementary tables to CSV",
    "text": "09.18-10.08, 10.18-11.38: Converting supplementary tables to CSV\nCopied each table into LibreOffice Calc and saved as CSV.\nAs all tables had the same structure, I wrote a script that reformats them. This is so that they don’t “share” cells, and instead each row has all the information needed to identify it, making them easier to use and compare against later on.\nDisplayed these within the scope page.\n\n\n\n\n\n\nReflection\n\n\n\nThis took a longer than expected to reformat and sort, and so provision of tables in a “usable” format would have facilitated reproduction, although I understand that the tables that were provided are far more readable and easy to look at."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#updating-readme",
    "href": "logbook/posts/2024_07_22/index.html#updating-readme",
    "title": "Day 2",
    "section": "11.40-11.42: Updating README",
    "text": "11.40-11.42: Updating README\nModifying from template."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#checking-scope",
    "href": "logbook/posts/2024_07_22/index.html#checking-scope",
    "title": "Day 2",
    "section": "11.48-11.55: Checking scope",
    "text": "11.48-11.55: Checking scope\nHad another look over the paper to double check if I could spot anything that I think could be in scope.\nAppears likely that the supplementary tables might actually often contain the data used to produce the figures, which is handy, as if I weren’t able to reproduce the results themselves, I would still be able to use that data to produce the figures (potentially (?) unless we would want to do it from scratch).\nDid spot another result - “The strongest protective effect is seen with the N95 masks (nearly equivalent to a FFP2 mask), which has the effect of reducing the odds of transmission by 0.09.” - which, on reflection, might be an additional item for the scope, as the odds of transmission are not calculated/provided within the tables or figures.\nAll other text though seems to be interpreting the figures and tables presented, and not providing new results."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#consensus-on-scope-and-archive-repository",
    "href": "logbook/posts/2024_07_22/index.html#consensus-on-scope-and-archive-repository",
    "title": "Day 2",
    "section": "15.23-15.30, 15.38-15.40: Consensus on scope and archive repository",
    "text": "15.23-15.30, 15.38-15.40: Consensus on scope and archive repository\nMessaged with Tom who had a look over the scope and agreed he was happy with it. Also, happy with not emailing authors again re: starting reproduction.\nAlison also later confirmed she was likewise happy with the scope.\nUpdate CHANGELOG.md and CITATION.cff before then creating a release to archive the repository on Zenodo."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#look-over-code",
    "href": "logbook/posts/2024_07_22/index.html#look-over-code",
    "title": "Day 2",
    "section": "15.41-15.42: Look over code",
    "text": "15.41-15.42: Look over code\nConcise / short model code, looks like it will run the model but will need to save results to csv and generate figures and tables with own code."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#set-up-environment",
    "href": "logbook/posts/2024_07_22/index.html#set-up-environment",
    "title": "Day 2",
    "section": "15.44-15.56: Set-up environment",
    "text": "15.44-15.56: Set-up environment\nThe article mentions that code was in Python 3 and uses numpy and pandas. Looking at code, those do appear to be the only packages required that are not base (only other is random which is base). Looking at dates:\n\nArticle published online: 12 Sep 2020\nCode put on GitHub: 29 Aug 2020\n\nHence, will base specific python version and package versions on being on or prior to 29 August 2020.\n\nPython - 3.8 (first release 14 Oct 2019, then 3.9 came in Oct 2020)\nNumpy - 1.19.1 (21 July 2020, https://pypi.org/project/numpy/#history)\nPandas - 1.1.1 (28 July 2020, https://pypi.org/project/pandas/#history)\n\nCreated an environment file and installed with mamba - mamba env create -f environment.yaml. Once activated enviroment, once activated with mamba activate lim2020, can see with conda list python that we have python 3.8.19. Checking online, can see should switch to 3.8.5, which is version from 20 July 2020."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#run-model",
    "href": "logbook/posts/2024_07_22/index.html#run-model",
    "title": "Day 2",
    "section": "15.57-15.58, 16.01-16.05, 16.15-16.33, 16.36-16.45, 17.15-17.16, 18.57-18.58: Run model",
    "text": "15.57-15.58, 16.01-16.05, 16.15-16.33, 16.36-16.45, 17.15-17.16, 18.57-18.58: Run model\nCopied Roster Schedule COVID Simulation-final.py and renamed to model.py. Created reproduction.ipynb to run model and then produce outputs, and add ipykernel to environment (required for .ipynb).\nThen ran the model. Whilst it ran, it printed lots of SettingWithCopyWarning errors for stafflist['infected'][staff_infected[i]]=1 and stafflist['infected'][roster.iloc[0][0]]=1. (SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.) I anticipate these could be resolved with the following changes (which I’ll implement once it’s finished running):\n\nstafflist.loc[staff_infected[i], 'infected'] = 1\nstafflist.loc[roster.iloc[0][0], 'infected'] = 1\n\nWasn’t certain how long model should take, but paused record of time whilst it ran. After 10 minutes though, I decided to cancel that, and instead just run one version of the input parameters for the model (i.e. one choice from staff per shift, shifts per day, strength, staff change).\nI copied over the functions into the .ipynb and ran one version of model. Can see this outputs a table where columns are the strength and staff change. I tried running a few to understand how the results table was being produced. I then add code to save the results to .csv.\nPresently, I think this might only be for one shift per day, although I might be wrong.\nOnce home, set model to run the full loop from the .py script. This took 19 minutes 8 seconds.\n\n\n\n\n\n\nReflection\n\n\n\nModel run time does have an impact on how easy it is to rerun (or then reuse) a model."
  },
  {
    "objectID": "logbook/posts/2024_07_22/index.html#timings",
    "href": "logbook/posts/2024_07_22/index.html#timings",
    "title": "Day 2",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 82\n\n# Times from today\ntimes = [\n    ('9.18', '10.08'),\n    ('10.18', '11.38'),\n    ('11.40', '11.42'),\n    ('11.48', '11.55'),\n    ('15.23', '15.30'),\n    ('15.38', '15.40'),\n    ('15.41', '15.42'),\n    ('15.44', '15.56'),\n    ('15.57', '15.58'),\n    ('16.01', '16.05'),\n    ('16.15', '16.33'),\n    ('16.36', '16.45'),\n    ('17.15', '17.16'),\n    ('18.57', '18.58')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 195m, or 3h 15m\nTotal used to date: 277m, or 4h 37m\nTime remaining: 2123m, or 35h 23m\nUsed 11.5% of 40 hours max"
  },
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "Of the 9 items in the scope, 100% (9 out of 9) were considered to be successfully reproduced.\nAs cited throughout, images on this page are sourced from Lim et al. (2020)\nDue to the size of the original tables, I have previewed the head of each, but then presented descriptive statistics from comparing all the values in each table."
  },
  {
    "objectID": "evaluation/reproduction_success.html#time-to-completion",
    "href": "evaluation/reproduction_success.html#time-to-completion",
    "title": "Reproduction success",
    "section": "Time-to-completion",
    "text": "Time-to-completion\nNon-interactive plot:\n\n\n\n\n\n\n\n\n\nInteractive plot:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-2",
    "href": "evaluation/reproduction_success.html#figure-2",
    "title": "Reproduction success",
    "section": "Figure 2",
    "text": "Figure 2\nConsensus: Successfully reproduced\nOriginal figure (Lim et al. (2020)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-3",
    "href": "evaluation/reproduction_success.html#figure-3",
    "title": "Reproduction success",
    "section": "Figure 3",
    "text": "Figure 3\nConsensus: Successfully reproduced\nOriginal figure (Lim et al. (2020)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-4",
    "href": "evaluation/reproduction_success.html#figure-4",
    "title": "Reproduction success",
    "section": "Figure 4",
    "text": "Figure 4\nConsensus: Successfully reproduced\nOriginal figure (Lim et al. (2020)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-5",
    "href": "evaluation/reproduction_success.html#figure-5",
    "title": "Reproduction success",
    "section": "Figure 5",
    "text": "Figure 5\nConsensus: Successfully reproduced\nOriginal figure (Lim et al. (2020)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplemental-table-2",
    "href": "evaluation/reproduction_success.html#supplemental-table-2",
    "title": "Reproduction success",
    "section": "Supplemental Table 2",
    "text": "Supplemental Table 2\nConsensus: Successfully reproduced\nPreview of the reformatted original table (Lim et al. (2020)) alongside the reproduced table.\nThen, shares the results from calculating the absolute difference in the prop_infected row between the tables, and describes the observed differences.\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.20\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.20\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.40\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.30\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.20\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.20\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.20\n\n\n12\n7\n1\n5\n2\n3\n0.20\n\n\n24\n7\n1\n5\n2\n7\n0.40\n\n\n36\n7\n1\n5\n2\n14\n0.30\n\n\n48\n7\n1\n5\n2\n21\n0.30\n\n\n60\n7\n1\n5\n4\n1\n0.05\n\n\n72\n7\n1\n5\n4\n3\n0.10\n\n\n84\n7\n1\n5\n4\n7\n0.15\n\n\n96\n7\n1\n5\n4\n14\n0.15\n\n\n108\n7\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.008405\nstd        0.017549\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplemental-table-3",
    "href": "evaluation/reproduction_success.html#supplemental-table-3",
    "title": "Reproduction success",
    "section": "Supplemental Table 3",
    "text": "Supplemental Table 3\nConsensus: Successfully reproduced\nPreview of the reformatted original table (Lim et al. (2020)) alongside the reproduced table.\nThen, shares the results from calculating the absolute difference in the prop_infected row between the tables, and describes the observed differences.\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.10\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.10\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.20\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.10\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.20\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.05\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.05\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.10\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.05\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.05\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.10\n\n\n12\n7\n1\n5\n2\n3\n0.10\n\n\n24\n7\n1\n5\n2\n7\n0.10\n\n\n36\n7\n1\n5\n2\n14\n0.10\n\n\n48\n7\n1\n5\n2\n21\n0.10\n\n\n60\n7\n1\n5\n4\n1\n0.05\n\n\n72\n7\n1\n5\n4\n3\n0.05\n\n\n84\n7\n1\n5\n4\n7\n0.05\n\n\n96\n7\n1\n5\n4\n14\n0.05\n\n\n108\n7\n1\n5\n4\n21\n0.05\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.009905\nstd        0.017464\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplemental-table-4",
    "href": "evaluation/reproduction_success.html#supplemental-table-4",
    "title": "Reproduction success",
    "section": "Supplemental Table 4",
    "text": "Supplemental Table 4\nConsensus: Successfully reproduced\nPreview of the reformatted original table (Lim et al. (2020)) alongside the reproduced table.\nThen, shares the results from calculating the absolute difference in the prop_infected row between the tables, and describes the observed differences.\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.40\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.50\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.50\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.50\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.20\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.25\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.25\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.25\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.40\n\n\n12\n7\n1\n5\n2\n3\n0.40\n\n\n24\n7\n1\n5\n2\n7\n0.50\n\n\n36\n7\n1\n5\n2\n14\n0.50\n\n\n48\n7\n1\n5\n2\n21\n0.50\n\n\n60\n7\n1\n5\n4\n1\n0.10\n\n\n72\n7\n1\n5\n4\n3\n0.17\n\n\n84\n7\n1\n5\n4\n7\n0.25\n\n\n96\n7\n1\n5\n4\n14\n0.25\n\n\n108\n7\n1\n5\n4\n21\n0.25\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.004762\nstd        0.012765\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.000000\nmax        0.120000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplemental-table-5",
    "href": "evaluation/reproduction_success.html#supplemental-table-5",
    "title": "Reproduction success",
    "section": "Supplemental Table 5",
    "text": "Supplemental Table 5\nConsensus: Successfully reproduced\nPreview of the reformatted original table (Lim et al. (2020)) alongside the reproduced table.\nThen, shares the results from calculating the absolute difference in the prop_infected row between the tables, and describes the observed differences.\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.25\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.30\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.40\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.15\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.15\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.20\n\n\n4\n7\n1\n5\n2\n3\n0.30\n\n\n8\n7\n1\n5\n2\n7\n0.30\n\n\n12\n7\n1\n5\n2\n14\n0.40\n\n\n16\n7\n1\n5\n2\n21\n0.30\n\n\n20\n7\n1\n5\n4\n1\n0.05\n\n\n24\n7\n1\n5\n4\n3\n0.10\n\n\n28\n7\n1\n5\n4\n7\n0.15\n\n\n32\n7\n1\n5\n4\n14\n0.15\n\n\n36\n7\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    180.000000\nmean       0.012056\nstd        0.022614\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.020000\nmax        0.100000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplemental-table-6",
    "href": "evaluation/reproduction_success.html#supplemental-table-6",
    "title": "Reproduction success",
    "section": "Supplemental Table 6",
    "text": "Supplemental Table 6\nConsensus: Successfully reproduced\nPreview of the reformatted original table (Lim et al. (2020)) alongside the reproduced table.\nThen, shares the results from calculating the absolute difference in the prop_infected row between the tables, and describes the observed differences.\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\nGloves\n1.0\n5.0\n2\n1\n0.20\n\n\n1\nGloves\n1.0\n5.0\n2\n3\n0.20\n\n\n2\nGloves\n1.0\n5.0\n2\n7\n0.20\n\n\n3\nGloves\n1.0\n5.0\n2\n14\n0.30\n\n\n4\nGloves\n1.0\n5.0\n2\n21\n0.30\n\n\n5\nGloves\n1.0\n5.0\n4\n1\n0.05\n\n\n6\nGloves\n1.0\n5.0\n4\n3\n0.05\n\n\n7\nGloves\n1.0\n5.0\n4\n7\n0.10\n\n\n8\nGloves\n1.0\n5.0\n4\n14\n0.15\n\n\n9\nGloves\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n180\nGloves\n1\n5\n2\n1\n0.20\n\n\n192\nGloves\n1\n5\n2\n3\n0.20\n\n\n204\nGloves\n1\n5\n2\n7\n0.20\n\n\n216\nGloves\n1\n5\n2\n14\n0.30\n\n\n228\nGloves\n1\n5\n2\n21\n0.30\n\n\n240\nGloves\n1\n5\n4\n1\n0.05\n\n\n252\nGloves\n1\n5\n4\n3\n0.05\n\n\n264\nGloves\n1\n5\n4\n7\n0.10\n\n\n276\nGloves\n1\n5\n4\n14\n0.15\n\n\n288\nGloves\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    700.000000\nmean       0.006214\nstd        0.011161\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.050000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "STARS framework",
    "section": "",
    "text": "This page evaluates the extent to which the original study meets the recommendations from the STARS framework for the sharing of code and associated materials from discrete-event simulation models (Monks, Harper, and Mustafee (2024)).\nOf the 8 essential STARS components:\n\n2 were met fully (✅)\n6 were not met (❌)\n\nOf the 5 optional STARS components:\n\n5 were not met (❌)\n\n\n\n\n\n\n\n\n\n\nComponent\nDescription\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\n\nOpen license\nFree and open-source software (FOSS) license (e.g. MIT, GNU Public License (GPL))\n❌ Not met\nWas not met at point of publication, but kindly add to repository on request\n\n\nDependency management\nSpecify software libraries, version numbers and sources (e.g. dependency management tools like virtualenv, conda, poetry)\n❌ Not met\n-\n\n\nFOSS model\nCoded in FOSS language (e.g. R, Julia, Python)\n✅ Fully\nPython\n\n\nMinimum documentation\nMinimal instructions (e.g. in README) that overview (a) what model does, (b) how to install and run model to obtain results, and (c) how to vary parameters to run new experiments\n❌ Not met\nLots of helpful comments in the code itself to aid understanding of the code, but repository does not have instructions (in the code or otherwise) on how to run the model / providing background / etc.\n\n\nORCID\nORCID for each study author\n❌ Not met\n-\n\n\nCitation information\nInstructions on how to cite the research artefact (e.g. CITATION.cff file)\n❌ Not met\n-\n\n\nRemote code repository\nCode available in a remote code repository (e.g. GitHub, GitLab, BitBucket)\n✅ Fully\nGitHub - https://github.com/chaose5/COVID-roster-simulation\n\n\nOpen science archive\nCode stored in an open science archive with FORCE11 compliant citation and guaranteed persistance of digital artefacts (e.g. Figshare, Zenodo, the Open Science Framework (OSF), and the Computational Modeling in the Social and Ecological Sciences Network (CoMSES Net))\n❌ Not met\n-\n\n\nOptional components\n\n\n\n\n\nEnhanced documentation\nOpen and high quality documentation on how the model is implemented and works (e.g. via notebooks and markdown files, brought together using software like Quarto and Jupyter Book). Suggested content includes:• Plain english summary of project and model• Clarifying license• Citation instructions• Contribution instructions• Model installation instructions• Structured code walk through of model• Documentation of modelling cycle using TRACE• Annotated simulation reporting guidelines• Clear description of model validation including its intended purpose\n❌ Not met\n-\n\n\nDocumentation hosting\nHost documentation (e.g. with GitHub pages, GitLab pages, BitBucket Cloud, Quarto Pub)\n❌ Not met\n-\n\n\nOnline coding environment\nProvide an online environment where users can run and change code (e.g. BinderHub, Google Colaboratory, Deepnote)\n❌ Not met\n-\n\n\nModel interface\nProvide web application interface to the model so it is accessible to less technical simulation users\n❌ Not met\n-\n\n\nWeb app hosting\nHost web app online (e.g. Streamlit Community Cloud, ShinyApps hosting)\n❌ Not met\n-\n\n\n\n\n\n\n\nReferences\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882."
  },
  {
    "objectID": "evaluation/scope.html",
    "href": "evaluation/scope.html",
    "title": "Scope",
    "section": "",
    "text": "This page outlines the parts of the journal article which we will attempt to reproduce.\nAll images and quotes on this page are sourced from Lim et al. (2020)"
  },
  {
    "objectID": "evaluation/scope.html#within-scope",
    "href": "evaluation/scope.html#within-scope",
    "title": "Scope",
    "section": "Within scope",
    "text": "Within scope\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\nFigure 2. “Panels a, b and c show impact of different roster arrangements (number of shifts, number of staff per shift, total staff pool) on the proportion of staff infected by workplace transmission. The secondary attack rate is set at 15% with the stimulated staff working non-consecutive days. Panel d shows the effect of different secondary attack rates on proportion of staff infected.” Lim et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\nFigure 3. “Effect of number of staff per shift and of the number of shifts per day on the proportion of staff infected by workplace transmission. The secondary attack rate is set at 15% with the stimulated staff working non-consecutive days.” Lim et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\nFigure 4. “Effect of frequency of shift change (i.e. number of consecutive days worked) on the proportion of staff infected by workplace transmission. The secondary attack rate is set at 15% with 20 staff per shift.” Lim et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\n\n\n\nFigure 5. “Effect of a) split team arrangement, social distancing and b) personal protective equipment on the proportion of staff infected by workplace trans- mission. The data represents the impact of the individual interventions.” Lim et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 2\n\n\n\n\n\nSupplemental Table 2. “Proportion of simulated laboratory staff infected by COVID-19 in base scenario with 15% probability of secondary infection at the end of day 7, day 14 and day 21 of the simulation. In this base scenario, the simulated staff worked fixed alternating workdays (i.e. fixed consecutive days on, and fixed minimum consecutive days off). The results shown are the median of 100 cycles of simulation. NA = not available as the number of staff per shift is too low to simulate under the required conditions.” Lim et al. (2020)\nReformatted table:\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.20\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.20\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.40\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.30\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n535\n21\n3.0\n30.0\n6\n1\n0.80\n\n\n536\n21\n3.0\n30.0\n6\n3\n0.78\n\n\n537\n21\n3.0\n30.0\n6\n7\n0.39\n\n\n538\n21\n3.0\n30.0\n6\n14\n0.17\n\n\n539\n21\n3.0\n30.0\n6\n21\n0.17\n\n\n\n\n540 rows × 6 columns\n\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 3\n\n\n\n\n\nSupplemental Table 3. “Proportion of simulated laboratory staff infected by COVID-19 in base scenario with 5% probability of secondary infection at the end of day 7, day 14 and day 21 of the simulation. In this scenario, the simulated staff worked fixed alternating workdays (i.e. fixed consecutive days on, and fixed minimum consecutive days off). The results shown are the median of 100 cycles of simulation. NA = not available as the number of staff per shift was too low to simulate under the required conditions.” Lim et al. (2020)\nReformatted table:\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.10\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.10\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.20\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.10\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.20\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n535\n21\n3.0\n30.0\n6\n1\n0.06\n\n\n536\n21\n3.0\n30.0\n6\n3\n0.11\n\n\n537\n21\n3.0\n30.0\n6\n7\n0.22\n\n\n538\n21\n3.0\n30.0\n6\n14\n0.17\n\n\n539\n21\n3.0\n30.0\n6\n21\n0.17\n\n\n\n\n540 rows × 6 columns\n\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 4\n\n\n\n\n\nSupplemental Table 4. “Proportion of simulated laboratory staff infected by COVID-19 in base scenario with 30% probability of secondary infection at the end of day 7, day 14 and day 21 of the simulation. In this scenario, the simulated staff worked fixed alternating workdays (i.e. fixed consecutive days on, and fixed minimum consecutive days off). The results shown are the median of 100 cycles of simulation. NA = not available as the number of staff per shift was too low to simulate under the required conditions.” Lim et al. (2020)\nReformatted table:\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.40\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.50\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.50\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.50\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n535\n21\n3.0\n30.0\n6\n1\n0.99\n\n\n536\n21\n3.0\n30.0\n6\n3\n0.91\n\n\n537\n21\n3.0\n30.0\n6\n7\n0.39\n\n\n538\n21\n3.0\n30.0\n6\n14\n0.17\n\n\n539\n21\n3.0\n30.0\n6\n21\n0.17\n\n\n\n\n540 rows × 6 columns\n\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 5\n\n\n\n\n\nSupplemental Table 5. “Proportion of simulated laboratory staff working in a single shift infected by COVID-19 in a scenario with 15% probability of secondary infection at the end of day 7, day 14 and day 21 of the simulation without predefined minimum rest day (i.e. random shift assignment after each shift). The results shown are the median of 100 cycles of simulation.” Lim et al. (2020)\nReformatted table:\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.25\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.30\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.40\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n175\n21\n1.0\n30.0\n6\n1\n0.59\n\n\n176\n21\n1.0\n30.0\n6\n3\n0.67\n\n\n177\n21\n1.0\n30.0\n6\n7\n0.42\n\n\n178\n21\n1.0\n30.0\n6\n14\n0.31\n\n\n179\n21\n1.0\n30.0\n6\n21\n0.17\n\n\n\n\n180 rows × 6 columns\n\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 6\n\n\n\n\n\nSupplemental Table 6. “Proportion of simulated laboratory staff infected by COVID-19 in base scenario with 15% probability of secondary infection at the end of day 14 of the simulation with the staff observing workplace social distancing (by reducing the contact rate by half) and using various personal protective equipment. In this scenario, the simulated staff worked fixed alternating workdays (i.e. fixed consecutive days on, and fixed minimum consecutive days off). The results shown are the median of 100 cycles of simulation. NA = not available as the number of staff per shift is too low to simulate under the required conditions.” Lim et al. (2020)\nReformatted table:\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\nGloves\n1.0\n5.0\n2\n1\n0.20\n\n\n1\nGloves\n1.0\n5.0\n2\n3\n0.20\n\n\n2\nGloves\n1.0\n5.0\n2\n7\n0.20\n\n\n3\nGloves\n1.0\n5.0\n2\n14\n0.30\n\n\n4\nGloves\n1.0\n5.0\n2\n21\n0.30\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n895\nSurgical mask\n3.0\n30.0\n6\n1\n0.02\n\n\n896\nSurgical mask\n3.0\n30.0\n6\n3\n0.05\n\n\n897\nSurgical mask\n3.0\n30.0\n6\n7\n0.08\n\n\n898\nSurgical mask\n3.0\n30.0\n6\n14\n0.16\n\n\n899\nSurgical mask\n3.0\n30.0\n6\n21\n0.16\n\n\n\n\n900 rows × 6 columns"
  },
  {
    "objectID": "evaluation/scope.html#outside-scope",
    "href": "evaluation/scope.html#outside-scope",
    "title": "Scope",
    "section": "Outside scope",
    "text": "Outside scope\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nFigure 1. “Visual representation of the simulation model. Panel a shows the two states a simulated staff can be in, namely staying at home or working in the laboratory with 4 colleagues (5-staff shift). Panel b shows the Poisson distribution from which the susceptible colleagues are drawn from”. Lim et al. (2020)\n\n\n\n\n\n\n\n\n\n\n\nSupplemental Table 1\n\n\n\n\n\n\n\n\nSupplemental Table 1. “Key simulation parameters used in this study.” Lim et al. (2020)"
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Summary report",
    "section": "",
    "text": "Lim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nThis is a discrete-event simulation modelling the transmission of COVID-19 in laboratory. It examines the proportion of staff infected in scenarios varying the: number of shifts per day; number of staff per shift; overall staff pool; shift patterns; secondary attack rate of the virus; introduction of protective measures (social distancing and personal protective equipment). The model is created using Python.\nImages from the original study on this page are soruced from Lim et al. (2020)"
  },
  {
    "objectID": "evaluation/reproduction_report.html#study",
    "href": "evaluation/reproduction_report.html#study",
    "title": "Summary report",
    "section": "",
    "text": "Lim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nThis is a discrete-event simulation modelling the transmission of COVID-19 in laboratory. It examines the proportion of staff infected in scenarios varying the: number of shifts per day; number of staff per shift; overall staff pool; shift patterns; secondary attack rate of the virus; introduction of protective measures (social distancing and personal protective equipment). The model is created using Python.\nImages from the original study on this page are soruced from Lim et al. (2020)"
  },
  {
    "objectID": "evaluation/reproduction_report.html#computational-reproducibility",
    "href": "evaluation/reproduction_report.html#computational-reproducibility",
    "title": "Summary report",
    "section": "Computational reproducibility",
    "text": "Computational reproducibility\nSuccessfully reproduced 9 out of 9 (100%) of items from the scope in 12h 27m (31.1%).\nRequired troubleshooting:\n\nTables - convert to .csv and long format\nEnvironment - identify appropriate versions and create environment file\nModel run time - add parallel processing to help reduce it\nSet up model so scenarios can be run programmatically - as function inputs rather than hard-coded values in the model script\nAdding parameters and scenarios - modifying existing parameters, switching hard-coded parameters to function inputs, or modifying code (e.g. adding conditional logic to skip or change what code is run)\nCreate figures - from scratch as no code provided\n\n\nFigure 2Figure 3Figure 4Figure 5Supplemental Table 2Supplemental Table 3Supplemental Table 4Supplemental Table 5Supplemental Table 6\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.20\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.20\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.40\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.30\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.20\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.20\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.20\n\n\n12\n7\n1\n5\n2\n3\n0.20\n\n\n24\n7\n1\n5\n2\n7\n0.40\n\n\n36\n7\n1\n5\n2\n14\n0.30\n\n\n48\n7\n1\n5\n2\n21\n0.30\n\n\n60\n7\n1\n5\n4\n1\n0.05\n\n\n72\n7\n1\n5\n4\n3\n0.10\n\n\n84\n7\n1\n5\n4\n7\n0.15\n\n\n96\n7\n1\n5\n4\n14\n0.15\n\n\n108\n7\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.008405\nstd        0.017549\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.10\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.10\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.20\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.10\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.20\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.05\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.05\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.10\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.05\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.05\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.10\n\n\n12\n7\n1\n5\n2\n3\n0.10\n\n\n24\n7\n1\n5\n2\n7\n0.10\n\n\n36\n7\n1\n5\n2\n14\n0.10\n\n\n48\n7\n1\n5\n2\n21\n0.10\n\n\n60\n7\n1\n5\n4\n1\n0.05\n\n\n72\n7\n1\n5\n4\n3\n0.05\n\n\n84\n7\n1\n5\n4\n7\n0.05\n\n\n96\n7\n1\n5\n4\n14\n0.05\n\n\n108\n7\n1\n5\n4\n21\n0.05\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.009905\nstd        0.017464\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.40\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.50\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.50\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.50\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.20\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.25\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.25\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.25\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.40\n\n\n12\n7\n1\n5\n2\n3\n0.40\n\n\n24\n7\n1\n5\n2\n7\n0.50\n\n\n36\n7\n1\n5\n2\n14\n0.50\n\n\n48\n7\n1\n5\n2\n21\n0.50\n\n\n60\n7\n1\n5\n4\n1\n0.10\n\n\n72\n7\n1\n5\n4\n3\n0.17\n\n\n84\n7\n1\n5\n4\n7\n0.25\n\n\n96\n7\n1\n5\n4\n14\n0.25\n\n\n108\n7\n1\n5\n4\n21\n0.25\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    420.000000\nmean       0.004762\nstd        0.012765\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.000000\nmax        0.120000\nName: diff, dtype: float64\n\n\n\n\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1.0\n5.0\n2\n1\n0.25\n\n\n1\n7\n1.0\n5.0\n2\n3\n0.30\n\n\n2\n7\n1.0\n5.0\n2\n7\n0.30\n\n\n3\n7\n1.0\n5.0\n2\n14\n0.30\n\n\n4\n7\n1.0\n5.0\n2\n21\n0.40\n\n\n5\n7\n1.0\n5.0\n4\n1\n0.10\n\n\n6\n7\n1.0\n5.0\n4\n3\n0.10\n\n\n7\n7\n1.0\n5.0\n4\n7\n0.15\n\n\n8\n7\n1.0\n5.0\n4\n14\n0.15\n\n\n9\n7\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nend_of_day\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\n7\n1\n5\n2\n1\n0.20\n\n\n4\n7\n1\n5\n2\n3\n0.30\n\n\n8\n7\n1\n5\n2\n7\n0.30\n\n\n12\n7\n1\n5\n2\n14\n0.40\n\n\n16\n7\n1\n5\n2\n21\n0.30\n\n\n20\n7\n1\n5\n4\n1\n0.05\n\n\n24\n7\n1\n5\n4\n3\n0.10\n\n\n28\n7\n1\n5\n4\n7\n0.15\n\n\n32\n7\n1\n5\n4\n14\n0.15\n\n\n36\n7\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    180.000000\nmean       0.012056\nstd        0.022614\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.020000\nmax        0.100000\nName: diff, dtype: float64\n\n\n\n\n\n\n'Preview of original'\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n0\nGloves\n1.0\n5.0\n2\n1\n0.20\n\n\n1\nGloves\n1.0\n5.0\n2\n3\n0.20\n\n\n2\nGloves\n1.0\n5.0\n2\n7\n0.20\n\n\n3\nGloves\n1.0\n5.0\n2\n14\n0.30\n\n\n4\nGloves\n1.0\n5.0\n2\n21\n0.30\n\n\n5\nGloves\n1.0\n5.0\n4\n1\n0.05\n\n\n6\nGloves\n1.0\n5.0\n4\n3\n0.05\n\n\n7\nGloves\n1.0\n5.0\n4\n7\n0.10\n\n\n8\nGloves\n1.0\n5.0\n4\n14\n0.15\n\n\n9\nGloves\n1.0\n5.0\n4\n21\n0.15\n\n\n\n\n\n\n\n'Preview of reproduction'\n\n\n\n\n\n\n\n\n\nworkplace_measure\nshifts_per_day\nstaff_per_shift\nstrength\nstaff_change\nprop_infected\n\n\n\n\n180\nGloves\n1\n5\n2\n1\n0.20\n\n\n192\nGloves\n1\n5\n2\n3\n0.20\n\n\n204\nGloves\n1\n5\n2\n7\n0.20\n\n\n216\nGloves\n1\n5\n2\n14\n0.30\n\n\n228\nGloves\n1\n5\n2\n21\n0.30\n\n\n240\nGloves\n1\n5\n4\n1\n0.05\n\n\n252\nGloves\n1\n5\n4\n3\n0.05\n\n\n264\nGloves\n1\n5\n4\n7\n0.10\n\n\n276\nGloves\n1\n5\n4\n14\n0.15\n\n\n288\nGloves\n1\n5\n4\n21\n0.15\n\n\n\n\n\n\n\n'Absolute differences in proportion infected between tables'\n\n\ncount    700.000000\nmean       0.006214\nstd        0.011161\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.010000\nmax        0.050000\nName: diff, dtype: float64"
  },
  {
    "objectID": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "href": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "title": "Summary report",
    "section": "Evaluation against guidelines",
    "text": "Evaluation against guidelines\n\n\n                                                \n\n\nContext: The original study repository was evaluated against criteria from journal badges relating to how open and reproducible the model is and against guidance for sharing artefacts from the STARS framework. The original study article and supplementary materials (excluding code) were evaluated against reporting guidelines for DES models: STRESS-DES, and guidelines adapted from ISPOR-SDM."
  },
  {
    "objectID": "quarto_site/license.html",
    "href": "quarto_site/license.html",
    "title": "Open Source License",
    "section": "",
    "text": "This repository is licensed under an MIT license.\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nThis is aligned with the original study, who shared their code under an MIT license.\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2020 Lim, C. Y., Bohn, M. K., Lippi, G., Ferrari, M., Loh, T. P., Yuen, K. Y., Adeli, K., Horvath, A. R., & IFCC Task Force on COVID-19.\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nThe original study was published in the journal “Clinical Biochemistry”, which was shared with PubMed Central (PMC) and made free to view online at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7486214/.\n\n\n\n\n\n\nView copyright statement from journal\n\n\n\n\n\n“Copyright © 2020 The Canadian Society of Clinical Chemists. Published by Elsevier Inc. All rights reserved. Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company’s public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.”\nSince the COVID-19 resource centre remains active, we understand that this means we are free to upload this article and its supplementary materials to this repository, and to use images from this article with attribution."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html",
    "href": "quarto_site/reproduction_readme.html",
    "title": "README for reproduction",
    "section": "",
    "text": "Lim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nThis is a discrete-event simulation modelling the transmission of COVID-19 in laboratory. It examines the proportion of staff infected in scenarios varying the: number of shifts per day; number of staff per shift; overall staff pool; shift patterns; secondary attack rate of the virus; introduction of protective measures (social distancing and personal protective equipment). The model is created using Python.\n\n\n\nIn this assessment, we attempted to reproduce 9 items: 4 figures and 5 tables.\n\n\n\n\n\n├── docker\n│   └──  ...\n├── outputs\n│   └──  ...\n├── scripts\n│   └──  ...\n├── tests\n│   └──  ...\n├── environment.yaml\n└── README.md\n\ndocker/ - Instructions for creation of Docker container.\noutputs/ - Output files from the model.\nscripts/ - Code for the model and for reproducing items from the scope.\ntests/ - Test to check that model produces consistent results with our reproduction.\nenvironment.yaml - Instructions for creation of python environment.\nREADME.md - This file!\n\n\n\n\n\n\nA conda/mamba environment has been provided. To create this environment on your machine, you should run this command in your terminal:\nconda env create -f environment.yaml\nYou can then use this environment in your preferred IDE, such as VSCode (where you will be asked to select the kernel/interpreter). You can activate it in the terminal by running:\nconda activate lim2020\nYou can run either of these commands also using mamba instead (e.g. mamba activate lim2020).\n\n\n\nA Dockerfile is provided, which you can use to build the Docker image. The docker image will include the correct version of Python and the packages, and an installation of jupyterlab which you can run from your browser. It will also include the scripts and outputs from this directory.\nFor this option (and option C), you’ll need to ensure that docker is installed on your machine.\nTo create the docker image and then open jupyter lab:\n\nIn the terminal, navigate to parent directory of the reproduction/ folder\nBuild the image:\n\nsudo docker build --tag lim2020 . -f ./reproduction/docker/Dockerfile\n\nCreate a docker container from that image and open jupyter lab:\n\n(sleep 2 && xdg-open http://localhost:8080) & sudo docker run -it -p 8080:80 --name lim2020_docker lim2020\n\n\n\nA pre-built image is available on the GitHub container registry. To use it:\n\nCreate a Personal Access Token (Classic) for your GitHub account with write:packages and delete:packages access\nOn terminal, run the following command and enter your sudo password (if prompted), followed by the token just generated (which acts as your GitHub password)\n\nsudo docker login ghcr.io -u githubusername\n\nDownload the image:\n\nsudo docker pull ghcr.io/pythonhealthdatascience/lim2020\n\nCreate container and open RStudio:\n\n(sleep 2 && xdg-open http://localhost:8080) & sudo docker run -it -p 8080:80 --name lim2020_docker ghcr.io/pythonhealthdatascience/lim2020:latest\n\n\n\n\n\n\nTo run all the model scenarios, open and execute the provided ipynb files in scripts/. You can do so within your preferred IDE (e.g. VSCode, JupyterLab).\n\n\n\nTwo of the model scenarios have been included as tests within tests/. You can run these by executing the following command from your terminal whilst in the reproduction/ directory with the lim2020 environment active:\npytest\nThis will run the two scenarios and compare the results against those we have saved. Although this will not produce any figures from the paper, and will not run all the scenarios, it will allow you to check if you are getting results consistent with our reproduction, on your own machine.\nOnce the tests begin to run, you should see information indicating the test has started, but then should expect to see no further updates to the screen until both tests have completed.\nExample of output when start tests:\n=========================================================================== test session starts ============================================================================\nplatform linux -- Python 3.8.5, pytest-7.4.4, pluggy-1.0.0\nrootdir: /home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction\nplugins: xdist-3.6.1\ncollected 2 items                                                                                                                                                          \n\ntests/test_model.py .. \nExample of finished tests (if both tests passed):\n============= 2 passed, 9 warnings in 395.17s (0:06:35) =============\n\n\n\n\n\nThis reproduction was conducted on an Intel Core i7-12700H with 32GB RAM running Ubuntu 22.04.4 Linux.\nOn that machine, running all scenarios from scratch, the total run time is 49 minutes and 17 seconds.\nRun time for the tests was 6 minutes 35 seconds.\n\n\n\nTo cite the original study, please refer to the reference above. To cite this reproduction, please refer to the CITATION.cff file in the parent folder.\n\n\n\nThis repository is licensed under the MIT License."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#model-summary",
    "href": "quarto_site/reproduction_readme.html#model-summary",
    "title": "README for reproduction",
    "section": "",
    "text": "Lim CY, Bohn MK, Lippi G, Ferrari M, Loh TP, Yuen K, Adeli K, Horvath AR Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study. Clinical Biochemistry 86:15-22 (2020). https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\nThis is a discrete-event simulation modelling the transmission of COVID-19 in laboratory. It examines the proportion of staff infected in scenarios varying the: number of shifts per day; number of staff per shift; overall staff pool; shift patterns; secondary attack rate of the virus; introduction of protective measures (social distancing and personal protective equipment). The model is created using Python."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "href": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "title": "README for reproduction",
    "section": "",
    "text": "In this assessment, we attempted to reproduce 9 items: 4 figures and 5 tables."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "href": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "title": "README for reproduction",
    "section": "",
    "text": "├── docker\n│   └──  ...\n├── outputs\n│   └──  ...\n├── scripts\n│   └──  ...\n├── tests\n│   └──  ...\n├── environment.yaml\n└── README.md\n\ndocker/ - Instructions for creation of Docker container.\noutputs/ - Output files from the model.\nscripts/ - Code for the model and for reproducing items from the scope.\ntests/ - Test to check that model produces consistent results with our reproduction.\nenvironment.yaml - Instructions for creation of python environment.\nREADME.md - This file!\n\n\n\n\n\n\nA conda/mamba environment has been provided. To create this environment on your machine, you should run this command in your terminal:\nconda env create -f environment.yaml\nYou can then use this environment in your preferred IDE, such as VSCode (where you will be asked to select the kernel/interpreter). You can activate it in the terminal by running:\nconda activate lim2020\nYou can run either of these commands also using mamba instead (e.g. mamba activate lim2020).\n\n\n\nA Dockerfile is provided, which you can use to build the Docker image. The docker image will include the correct version of Python and the packages, and an installation of jupyterlab which you can run from your browser. It will also include the scripts and outputs from this directory.\nFor this option (and option C), you’ll need to ensure that docker is installed on your machine.\nTo create the docker image and then open jupyter lab:\n\nIn the terminal, navigate to parent directory of the reproduction/ folder\nBuild the image:\n\nsudo docker build --tag lim2020 . -f ./reproduction/docker/Dockerfile\n\nCreate a docker container from that image and open jupyter lab:\n\n(sleep 2 && xdg-open http://localhost:8080) & sudo docker run -it -p 8080:80 --name lim2020_docker lim2020\n\n\n\nA pre-built image is available on the GitHub container registry. To use it:\n\nCreate a Personal Access Token (Classic) for your GitHub account with write:packages and delete:packages access\nOn terminal, run the following command and enter your sudo password (if prompted), followed by the token just generated (which acts as your GitHub password)\n\nsudo docker login ghcr.io -u githubusername\n\nDownload the image:\n\nsudo docker pull ghcr.io/pythonhealthdatascience/lim2020\n\nCreate container and open RStudio:\n\n(sleep 2 && xdg-open http://localhost:8080) & sudo docker run -it -p 8080:80 --name lim2020_docker ghcr.io/pythonhealthdatascience/lim2020:latest\n\n\n\n\n\n\nTo run all the model scenarios, open and execute the provided ipynb files in scripts/. You can do so within your preferred IDE (e.g. VSCode, JupyterLab).\n\n\n\nTwo of the model scenarios have been included as tests within tests/. You can run these by executing the following command from your terminal whilst in the reproduction/ directory with the lim2020 environment active:\npytest\nThis will run the two scenarios and compare the results against those we have saved. Although this will not produce any figures from the paper, and will not run all the scenarios, it will allow you to check if you are getting results consistent with our reproduction, on your own machine.\nOnce the tests begin to run, you should see information indicating the test has started, but then should expect to see no further updates to the screen until both tests have completed.\nExample of output when start tests:\n=========================================================================== test session starts ============================================================================\nplatform linux -- Python 3.8.5, pytest-7.4.4, pluggy-1.0.0\nrootdir: /home/amy/Documents/stars/stars-reproduce-lim-2020/reproduction\nplugins: xdist-3.6.1\ncollected 2 items                                                                                                                                                          \n\ntests/test_model.py .. \nExample of finished tests (if both tests passed):\n============= 2 passed, 9 warnings in 395.17s (0:06:35) ============="
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "href": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "title": "README for reproduction",
    "section": "",
    "text": "This reproduction was conducted on an Intel Core i7-12700H with 32GB RAM running Ubuntu 22.04.4 Linux.\nOn that machine, running all scenarios from scratch, the total run time is 49 minutes and 17 seconds.\nRun time for the tests was 6 minutes 35 seconds."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#citation",
    "href": "quarto_site/reproduction_readme.html#citation",
    "title": "README for reproduction",
    "section": "",
    "text": "To cite the original study, please refer to the reference above. To cite this reproduction, please refer to the CITATION.cff file in the parent folder."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#license",
    "href": "quarto_site/reproduction_readme.html#license",
    "title": "README for reproduction",
    "section": "",
    "text": "This repository is licensed under the MIT License."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. Dates formatted as YYYY-MM-DD as per ISO standard.\n\n\nConducted reproduction, evaluated code and article, organised research compendium, and test run by second STARS team member.\n\n\n\nReproduction of the model in reproduction/\nEvaluation of the code and article against guidelines (in evaluation/)\nSummary report and reflections from reproduction\nOrganised and documented reproduction to form a research compendium\nTest-run of model by Tom Monks, attempting to run code from reproduction/\n\n\n\n\n\nRemoved one item from the scope - in-text result 1: “The strongest protective effect is seen with the N95 masks (nearly equivalent to a FFP2 mask), which has the effect of reducing the odds of transmission by 0.09”. This was because I realised that this was not in fact a result, but just a statement of the parameter used in the model (to simulate the effect of wearing masks, you reduce the odds of transmission (p=0.15) by 0.09 (p=0.15*0.09) when you run the model).\n\n\n\n\n\nSet up repository and defined scope of reproduction.\n\n\n\nCode from original study\nArticle and supplementary materials\nReformatted csv tables from the supplementary materials\nPlanned scope for reproduction\n\n\n\n\n\nModified template to be about Lim et al. 2020"
  },
  {
    "objectID": "CHANGELOG.html#v0.2.0---2024-10-02",
    "href": "CHANGELOG.html#v0.2.0---2024-10-02",
    "title": "Changelog",
    "section": "",
    "text": "Conducted reproduction, evaluated code and article, organised research compendium, and test run by second STARS team member.\n\n\n\nReproduction of the model in reproduction/\nEvaluation of the code and article against guidelines (in evaluation/)\nSummary report and reflections from reproduction\nOrganised and documented reproduction to form a research compendium\nTest-run of model by Tom Monks, attempting to run code from reproduction/\n\n\n\n\n\nRemoved one item from the scope - in-text result 1: “The strongest protective effect is seen with the N95 masks (nearly equivalent to a FFP2 mask), which has the effect of reducing the odds of transmission by 0.09”. This was because I realised that this was not in fact a result, but just a statement of the parameter used in the model (to simulate the effect of wearing masks, you reduce the odds of transmission (p=0.15) by 0.09 (p=0.15*0.09) when you run the model)."
  },
  {
    "objectID": "CHANGELOG.html#v0.1.0---2024-07-22",
    "href": "CHANGELOG.html#v0.1.0---2024-07-22",
    "title": "Changelog",
    "section": "",
    "text": "Set up repository and defined scope of reproduction.\n\n\n\nCode from original study\nArticle and supplementary materials\nReformatted csv tables from the supplementary materials\nPlanned scope for reproduction\n\n\n\n\n\nModified template to be about Lim et al. 2020"
  }
]